{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Copy of Run Self Defined Problem.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9eyPoPWiwSn"
      },
      "source": [
        "## Define new problem type and data reading function\n",
        "\n",
        "We'll use IMDB dataset as example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZTKo7NqjBwY"
      },
      "source": [
        "!pip install tensorflow-gpu\n",
        "!pip install tensorflow-addons==0.11.2\n",
        "!pip install bert-multitask-learning==0.5.7b8\n",
        "!pip install transformers==3.5.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek6GxaaCiwSn"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQCSaxliiwSo"
      },
      "source": [
        "from bert_multitask_learning import (train_bert_multitask, \n",
        "                                     eval_bert_multitask, DynamicBatchSizeParams, TRAIN, EVAL, PREDICT, preprocessing_fn, get_or_make_label_encoder)\n",
        "import pickle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2y6g4NZiwSo"
      },
      "source": [
        "new_problem_type = {'imdb_cls': 'cls'}\n",
        "\n",
        "@preprocessing_fn\n",
        "def imdb_cls(params, mode):\n",
        "\n",
        "    # get data\n",
        "    (train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data(num_words=10000)\n",
        "    label_encoder = get_or_make_label_encoder(params, 'imdb_cls', mode, train_labels+test_labels)\n",
        "    word_to_id = keras.datasets.imdb.get_word_index()\n",
        "    index_from=3\n",
        "    word_to_id = {k:(v+index_from) for k,v in word_to_id.items()}\n",
        "    word_to_id[\"<PAD>\"] = 0\n",
        "    word_to_id[\"<START>\"] = 1\n",
        "    word_to_id[\"<UNK>\"] = 2\n",
        "    id_to_word = {value:key for key,value in word_to_id.items()}\n",
        "\n",
        "    train_data = [[id_to_word[i] for i in sentence] for sentence in train_data]\n",
        "    test_data = [[id_to_word[i] for i in sentence] for sentence in test_data]\n",
        "    \n",
        "    if mode == TRAIN:\n",
        "        input_list = train_data\n",
        "        target_list = train_labels\n",
        "    else:\n",
        "        input_list = test_data\n",
        "        target_list = test_labels\n",
        "    \n",
        "    return input_list, target_list\n",
        "new_problem_process_fn_dict = {'imdb_cls': imdb_cls}\n",
        "    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrcMraPLiwSo"
      },
      "source": [
        "## Train Model\n",
        "\n",
        "Please make sure you're using the correct checkpoint to initialize model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi4hvvd_iwSo"
      },
      "source": [
        "params = DynamicBatchSizeParams()\n",
        "params.transformer_config_loading = 'BertConfig'\n",
        "params.transformer_model_name = 'bert-base-chinese'\n",
        "params.transformer_tokenizer_name = 'bert-base-chinese'\n",
        "params.transformer_tokenizer_loading = 'BertTokenizer'\n",
        "train_bert_multitask(problem='imdb_cls', num_gpus=1, \n",
        "                     num_epochs=1, params=params, \n",
        "                     problem_type_dict=new_problem_type, processing_fn_dict=new_problem_process_fn_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mp_uEWTloEi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}