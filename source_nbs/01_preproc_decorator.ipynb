{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp preproc_decorator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Decorator\n",
    "\n",
    "A decorator to simplify data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import logging\n",
    "from types import GeneratorType\n",
    "from typing import Callable\n",
    "from inspect import signature\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from bert_multitask_learning.read_write_tfrecord import (write_single_problem_chunk_tfrecord,\n",
    "                                  write_single_problem_gen_tfrecord)\n",
    "from bert_multitask_learning.special_tokens import PREDICT\n",
    "from bert_multitask_learning.utils import LabelEncoder, get_or_make_label_encoder, load_transformer_tokenizer\n",
    "\n",
    "\n",
    "def preprocessing_fn(func: Callable):\n",
    "    \"\"\"Usually used as a decorator.\n",
    "\n",
    "    The input and output signature of decorated function should be:\n",
    "    func(params: bert_multitask_learning.BaseParams,\n",
    "         mode: str) -> Union[Generator[X, y], Tuple[List[X], List[y]]]\n",
    "\n",
    "    Where X can be:\n",
    "    - Dicitionary of 'a' and 'b' texts: {'a': 'a test', 'b': 'b test'}\n",
    "    - Text: 'a test'\n",
    "    - Dicitionary of modalities: {'text': 'a test', 'image': np.array([1,2,3])}\n",
    "\n",
    "    Where y can be:\n",
    "    - Text or scalar: 'label_a'\n",
    "    - List of text or scalar: ['label_a', 'label_a1'] (for seq2seq and seq_tag)\n",
    "\n",
    "    This decorator will do the following things:\n",
    "    - load tokenizer\n",
    "    - call func, save as example_list\n",
    "    - create label_encoder and count the number of rows of example_list\n",
    "    - create bert features from example_list and write tfrecord\n",
    "\n",
    "    Args:\n",
    "        func (Callable): preprocessing function for problem\n",
    "    \"\"\"\n",
    "    def wrapper(params, mode, get_data_num=False, write_tfrecord=True):\n",
    "        problem = func.__name__\n",
    "\n",
    "        tokenizer = load_transformer_tokenizer(\n",
    "            params.transformer_tokenizer_name, params.transformer_tokenizer_loading)\n",
    "        proc_fn_signature_names = list(signature(\n",
    "            func).parameters.keys())\n",
    "\n",
    "        # proc func can return generator or tuple of lists\n",
    "        # and it can have an optional get_data_num argument to\n",
    "        # avoid iterate through the whole dataset to create\n",
    "        # label encoder and get number of rows of data\n",
    "        if len(proc_fn_signature_names) == 2:\n",
    "            example_list = func(params, mode)\n",
    "        else:\n",
    "            example_list = func(params, mode, get_data_num)\n",
    "\n",
    "        if isinstance(example_list, GeneratorType):\n",
    "            if get_data_num:\n",
    "                # create label encoder and data num\n",
    "                cnt = 0\n",
    "                label_list = []\n",
    "                logging.info(\n",
    "                    \"Preprocessing function returns generator, might take some time to create label encoder...\")\n",
    "                for example in example_list:\n",
    "                    if isinstance(example[0], int):\n",
    "                        data_num, label_encoder = example\n",
    "                        return data_num, None\n",
    "                    cnt += 1\n",
    "                    try:\n",
    "                        _, label = example\n",
    "                        label_list.append(label)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "\n",
    "                # create label encoder\n",
    "                label_encoder = get_or_make_label_encoder(\n",
    "                    params, problem=problem, mode=mode, label_list=label_list)\n",
    "\n",
    "                if label_encoder is None:\n",
    "                    return cnt, 0\n",
    "                if isinstance(label_encoder, LabelEncoder):\n",
    "                    return cnt, len(label_encoder.encode_dict)\n",
    "                if isinstance(label_encoder, MultiLabelBinarizer):\n",
    "                    return cnt, label_encoder.classes_.shape[0]\n",
    "\n",
    "                # label_encoder is tokenizer\n",
    "                try:\n",
    "                    return cnt, len(label_encoder.vocab)\n",
    "                except AttributeError:\n",
    "                    # models like xlnet's vocab size can only be retrieved from config instead of tokenizer\n",
    "                    return cnt, params.bert_decoder_config.vocab_size\n",
    "\n",
    "            else:\n",
    "                # create label encoder\n",
    "                label_encoder = get_or_make_label_encoder(\n",
    "                    params, problem=problem, mode=mode, label_list=[])\n",
    "\n",
    "            if mode == PREDICT:\n",
    "                return example_list, label_encoder\n",
    "\n",
    "            if write_tfrecord:\n",
    "                return write_single_problem_gen_tfrecord(\n",
    "                    func.__name__,\n",
    "                    example_list,\n",
    "                    label_encoder,\n",
    "                    params,\n",
    "                    tokenizer,\n",
    "                    mode)\n",
    "            else:\n",
    "                return {\n",
    "                    'problem': func.__name__,\n",
    "                    'gen': example_list,\n",
    "                    'label_encoder': label_encoder,\n",
    "                    'tokenizer': tokenizer\n",
    "                }\n",
    "\n",
    "        else:\n",
    "            # if proc func returns integer as the first element,\n",
    "            # that means it returns (num_of_data, label_encoder)\n",
    "            if isinstance(example_list[0], int):\n",
    "                data_num, label_encoder = example_list\n",
    "                inputs_list, target_list = None, None\n",
    "            else:\n",
    "                try:\n",
    "                    inputs_list, target_list = example_list\n",
    "                except ValueError:\n",
    "                    inputs_list = example_list\n",
    "                    target_list = None\n",
    "\n",
    "                label_encoder = get_or_make_label_encoder(\n",
    "                    params, problem=problem, mode=mode, label_list=target_list)\n",
    "                data_num = len(inputs_list)\n",
    "\n",
    "            if get_data_num:\n",
    "                if label_encoder is None:\n",
    "                    return data_num, 0\n",
    "                if isinstance(label_encoder, LabelEncoder):\n",
    "                    return data_num, len(label_encoder.encode_dict)\n",
    "                if isinstance(label_encoder, MultiLabelBinarizer):\n",
    "                    return data_num, label_encoder.classes_.shape[0]\n",
    "                if hasattr(label_encoder, 'vocab'):\n",
    "                    # label_encoder is tokenizer\n",
    "                    return data_num, len(label_encoder.vocab)\n",
    "                elif hasattr(params, 'decoder_vocab_size'):\n",
    "                    return data_num, params.decoder_vocab_size\n",
    "                else:\n",
    "                    raise ValueError('Cannot determine num of classes for problem {0}.'\n",
    "                                     'This is usually caused by {1} dose not has attribute vocab. In this case, you should manually specify vocab size to params: params.decoder_vocab_size = 32000'.format(problem, type(label_encoder).__name__))\n",
    "\n",
    "            if mode == PREDICT:\n",
    "                return inputs_list, target_list, label_encoder\n",
    "\n",
    "            if write_tfrecord:\n",
    "                return write_single_problem_chunk_tfrecord(\n",
    "                    func.__name__,\n",
    "                    inputs_list,\n",
    "                    target_list,\n",
    "                    label_encoder,\n",
    "                    params,\n",
    "                    tokenizer,\n",
    "                    mode)\n",
    "            else:\n",
    "                return {\n",
    "                    'problem': func.__name__,\n",
    "                    'inputs_list': inputs_list,\n",
    "                    'target_list': target_list,\n",
    "                    'label_encoder': label_encoder,\n",
    "                    'tokenizer': tokenizer\n",
    "                }\n",
    "\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Defined Preprocessing Function\n",
    "\n",
    "The user-defined preprocessing function should return two elements: features and targets, except for `pretrain` problem type.\n",
    "\n",
    "For features and targets, it can be one of the following format:\n",
    "- tuple of list\n",
    "- generator of tuple\n",
    "\n",
    "Please note that if preprocessing function returns generator of tuple, then corresponding problem cannot be chained using `&`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import bert_multitask_learning\n",
    "from bert_multitask_learning.params import BaseParams\n",
    "from typing import Tuple\n",
    "import shutil\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup params for testing\n",
    "params = BaseParams()\n",
    "params.ckpt_dir = tempfile.mkdtemp()\n",
    "params.tmp_file_dir = tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuple of List\n",
    "\n",
    "#### Single Modal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessing_fn\n",
    "def toy_cls(params: BaseParams, mode: str) -> Tuple[list, list]:\n",
    "    \"Simple example to demonstrate singe modal tuple of list return\"\n",
    "    if mode == bert_multitask_learning.TRAIN:\n",
    "        toy_input = ['this is a toy input' for _ in range(10)]\n",
    "        toy_target = ['a' for _ in range(10)]\n",
    "    else:\n",
    "        toy_input = ['this is a toy input for test' for _ in range(10)]\n",
    "        toy_target = ['a' for _ in range(10)]\n",
    "    return toy_input, toy_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "def preproc_dec_test():\n",
    "    params.add_problem(problem_name='toy_cls', problem_type='cls', processing_fn=toy_cls)\n",
    "    assert (10, 1)==toy_cls(params=params, mode=bert_multitask_learning.TRAIN, get_data_num=True, write_tfrecord=False)\n",
    "\n",
    "    toy_cls(params=params, mode=bert_multitask_learning.TRAIN, get_data_num=False, write_tfrecord=True)\n",
    "    assert os.path.exists(os.path.join(params.tmp_file_dir, 'toy_cls', 'train_feature_desc.json'))\n",
    "preproc_dec_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessing_fn\n",
    "def toy_cls(params: BaseParams, mode: str) -> Tuple[list, list]:\n",
    "    \"Simple example to demonstrate multi-modal tuple of list return\"\n",
    "    if mode == bert_multitask_learning.TRAIN:\n",
    "        toy_input = [{'text': 'this is a toy input', 'image': np.random.uniform(size=(16))} for _ in range(10)]\n",
    "        toy_target = ['a' for _ in range(10)]\n",
    "    else:\n",
    "        toy_input = [{'text': 'this is a toy input for test', 'image': np.random.uniform(size=(16))} for _ in range(10)]\n",
    "        toy_target = ['a' for _ in range(10)]\n",
    "    \n",
    "    return toy_input, toy_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.5809141  0.06545048 0.33736762 0.67150339 0.79172166 0.28670109\n",
      " 0.35819524 0.16445301 0.63652557 0.58635403 0.01462962 0.31659283\n",
      " 0.60157348 0.15251305 0.47542086 0.64718995]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.5809141  0.06545048 0.33736762 0.67150339 0.79172166 0.28670109\n",
      "  0.35819524 0.16445301 0.63652557 0.58635403 0.01462962 0.31659283\n",
      "  0.60157348 0.15251305 0.47542086 0.64718995]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n",
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.78141419 0.84232392 0.46107929 0.98250265 0.39704729 0.82511787\n",
      " 0.13924664 0.91397845 0.46385502 0.50603803 0.8973713  0.26643603\n",
      " 0.32537559 0.35824151 0.57058196 0.88571554]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.78141419 0.84232392 0.46107929 0.98250265 0.39704729 0.82511787\n",
      "  0.13924664 0.91397845 0.46385502 0.50603803 0.8973713  0.26643603\n",
      "  0.32537559 0.35824151 0.57058196 0.88571554]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n",
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.28702622 0.05779906 0.32058529 0.22609516 0.56083333 0.27525552\n",
      " 0.00651016 0.77114835 0.2351664  0.34067423 0.7223233  0.95391002\n",
      " 0.28508499 0.58622981 0.0891873  0.55953426]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.28702622 0.05779906 0.32058529 0.22609516 0.56083333 0.27525552\n",
      "  0.00651016 0.77114835 0.2351664  0.34067423 0.7223233  0.95391002\n",
      "  0.28508499 0.58622981 0.0891873  0.55953426]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n",
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.82587721 0.11180082 0.14669996 0.64719353 0.25423369 0.35193392\n",
      " 0.47871811 0.55146069 0.06024317 0.22885646 0.13044773 0.23379255\n",
      " 0.44464979 0.32199032 0.23943751 0.98479112]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.82587721 0.11180082 0.14669996 0.64719353 0.25423369 0.35193392\n",
      "  0.47871811 0.55146069 0.06024317 0.22885646 0.13044773 0.23379255\n",
      "  0.44464979 0.32199032 0.23943751 0.98479112]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n",
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.44006297 0.85989728 0.9389687  0.64114397 0.84473993 0.97948976\n",
      " 0.53785115 0.38839146 0.28561961 0.53547504 0.66682022 0.14020451\n",
      " 0.52502495 0.40704536 0.25863906 0.88478333]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.44006297 0.85989728 0.9389687  0.64114397 0.84473993 0.97948976\n",
      "  0.53785115 0.38839146 0.28561961 0.53547504 0.66682022 0.14020451\n",
      "  0.52502495 0.40704536 0.25863906 0.88478333]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n",
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.40619189 0.69805176 0.16382648 0.72553696 0.46950669 0.00133741\n",
      " 0.10918623 0.27992967 0.13272535 0.97199196 0.30722061 0.49006756\n",
      " 0.30990651 0.81747953 0.55464353 0.61606624]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.40619189 0.69805176 0.16382648 0.72553696 0.46950669 0.00133741\n",
      "  0.10918623 0.27992967 0.13272535 0.97199196 0.30722061 0.49006756\n",
      "  0.30990651 0.81747953 0.55464353 0.61606624]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n",
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.47052377 0.01818233 0.95122546 0.4226184  0.36430331 0.02733899\n",
      " 0.22505215 0.80242274 0.07984908 0.29730507 0.40595084 0.48736842\n",
      " 0.65548243 0.4842954  0.0593329  0.95553089]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.47052377 0.01818233 0.95122546 0.4226184  0.36430331 0.02733899\n",
      "  0.22505215 0.80242274 0.07984908 0.29730507 0.40595084 0.48736842\n",
      "  0.65548243 0.4842954  0.0593329  0.95553089]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n",
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.16758802 0.77036092 0.10716995 0.7037305  0.96344193 0.98818952\n",
      " 0.52648378 0.6418464  0.13481024 0.61512606 0.16794012 0.2718123\n",
      " 0.60376145 0.44267692 0.77463962 0.47573123]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.16758802 0.77036092 0.10716995 0.7037305  0.96344193 0.98818952\n",
      "  0.52648378 0.6418464  0.13481024 0.61512606 0.16794012 0.2718123\n",
      "  0.60376145 0.44267692 0.77463962 0.47573123]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n",
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.33392318 0.47154061 0.94996719 0.91745237 0.94070225 0.72784655\n",
      " 0.61108321 0.2270035  0.78180591 0.72479462 0.70959822 0.00929769\n",
      " 0.76197653 0.69656862 0.4505893  0.1118642 ]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.33392318 0.47154061 0.94996719 0.91745237 0.94070225 0.72784655\n",
      "  0.61108321 0.2270035  0.78180591 0.72479462 0.70959822 0.00929769\n",
      "  0.76197653 0.69656862 0.4505893  0.1118642 ]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n",
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.7240664  0.7228027  0.50156551 0.3812421  0.77850001 0.3816118\n",
      " 0.6603839  0.43776984 0.88894301 0.9975001  0.74698678 0.59841147\n",
      " 0.93658469 0.84227306 0.86368628 0.70076177]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.7240664  0.7228027  0.50156551 0.3812421  0.77850001 0.3816118\n",
      "  0.6603839  0.43776984 0.88894301 0.9975001  0.74698678 0.59841147\n",
      "  0.93658469 0.84227306 0.86368628 0.70076177]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "preproc_dec_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A, B Token Multi-modal\n",
    "\n",
    "TODO: Implement this. Not working yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "@preprocessing_fn\n",
    "def toy_cls(params: BaseParams, mode: str) -> Tuple[list, list]:\n",
    "    \"Simple example to demonstrate A, B token multi-modal tuple of list return\"\n",
    "    if mode == bert_multitask_learning.TRAIN:\n",
    "        toy_input = [\n",
    "            {\n",
    "                'a': {\n",
    "            'text': 'this is a toy input', \n",
    "            'image': np.random.uniform(size=(16))\n",
    "            },\n",
    "            'b':{\n",
    "            'text': 'this is a toy input', \n",
    "            'image': np.random.uniform(size=(16))\n",
    "            }\n",
    "            } for _ in range(10)]\n",
    "        toy_target = ['a' for _ in range(10)]\n",
    "    else:\n",
    "        toy_input = [\n",
    "            {\n",
    "                'a': {\n",
    "            'text': 'this is a toy input for test', \n",
    "            'image': np.random.uniform(size=(16))\n",
    "            },\n",
    "            'b':{\n",
    "            'text': 'this is a toy input for test', \n",
    "            'image': np.random.uniform(size=(16))\n",
    "            }\n",
    "            } for _ in range(10)]\n",
    "        toy_target = ['a' for _ in range(10)]\n",
    "    \n",
    "    return toy_input, toy_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hide\n",
    "# params.add_problem(problem_name='toy_cls', problem_type='cls', processing_fn=toy_cls)\n",
    "# assert (10, 1)==toy_cls(params=params, mode=bert_multitask_learning.TRAIN, get_data_num=True, write_tfrecord=False)\n",
    "\n",
    "# shutil.rmtree(os.path.join(params.tmp_file_dir, 'toy_cls'))\n",
    "# toy_cls(params=params, mode=bert_multitask_learning.TRAIN, get_data_num=False, write_tfrecord=True)\n",
    "# assert os.path.exists(os.path.join(params.tmp_file_dir, 'toy_cls', 'train_feature_desc.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator of Tuple\n",
    "\n",
    "#### Single Modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessing_fn\n",
    "def toy_cls(params: BaseParams, mode: str) -> Tuple[list, list]:\n",
    "    \"Simple example to demonstrate singe modal tuple of list return\"\n",
    "    if mode == bert_multitask_learning.TRAIN:\n",
    "        toy_input = ['this is a toy input' for _ in range(10)]\n",
    "        toy_target = ['a' for _ in range(10)]\n",
    "    else:\n",
    "        toy_input = ['this is a toy input for test' for _ in range(10)]\n",
    "        toy_target = ['a' for _ in range(10)]\n",
    "    for i, t in zip(toy_input, toy_target):\n",
    "        yield i, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:this is a toy input\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "preproc_dec_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessing_fn\n",
    "def toy_cls(params: BaseParams, mode: str) -> Tuple[list, list]:\n",
    "    \"Simple example to demonstrate multi-modal tuple of list return\"\n",
    "    if mode == bert_multitask_learning.TRAIN:\n",
    "        toy_input = [{'text': 'this is a toy input', 'image': np.random.uniform(size=(16))} for _ in range(10)]\n",
    "        toy_target = ['a' for _ in range(10)]\n",
    "    else:\n",
    "        toy_input = [{'text': 'this is a toy input for test', 'image': np.random.uniform(size=(16))} for _ in range(10)]\n",
    "        toy_target = ['a' for _ in range(10)]\n",
    "    for i, t in zip(toy_input, toy_target):\n",
    "        yield i, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.18114737 0.52025721 0.30680549 0.23567995 0.61244397 0.21831956\n",
      " 0.76148699 0.61470593 0.10734543 0.94891037 0.04046289 0.16569479\n",
      " 0.76607886 0.90692863 0.26102512 0.97853116]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.18114737 0.52025721 0.30680549 0.23567995 0.61244397 0.21831956\n",
      "  0.76148699 0.61470593 0.10734543 0.94891037 0.04046289 0.16569479\n",
      "  0.76607886 0.90692863 0.26102512 0.97853116]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n",
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.18484544 0.80277546 0.19575457 0.38967686 0.22814962 0.346866\n",
      " 0.69174051 0.62605842 0.62948146 0.01061797 0.38932132 0.52792525\n",
      " 0.05108438 0.26307339 0.33575207 0.20129576]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.18484544 0.80277546 0.19575457 0.38967686 0.22814962 0.346866\n",
      "  0.69174051 0.62605842 0.62948146 0.01061797 0.38932132 0.52792525\n",
      "  0.05108438 0.26307339 0.33575207 0.20129576]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n",
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.54728038 0.5950543  0.06254328 0.99421554 0.83262945 0.5288806\n",
      " 0.4014818  0.849738   0.19443848 0.83128857 0.76307971 0.83812551\n",
      " 0.97272375 0.49619905 0.3710877  0.28543082]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.54728038 0.5950543  0.06254328 0.99421554 0.83262945 0.5288806\n",
      "  0.4014818  0.849738   0.19443848 0.83128857 0.76307971 0.83812551\n",
      "  0.97272375 0.49619905 0.3710877  0.28543082]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n",
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.19430196 0.29670042 0.25438734 0.96091665 0.15482591 0.97279476\n",
      " 0.53343892 0.17266515 0.66480321 0.9147153  0.51323861 0.93866963\n",
      " 0.30901738 0.25641613 0.11465481 0.92900177]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.19430196 0.29670042 0.25438734 0.96091665 0.15482591 0.97279476\n",
      "  0.53343892 0.17266515 0.66480321 0.9147153  0.51323861 0.93866963\n",
      "  0.30901738 0.25641613 0.11465481 0.92900177]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n",
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.51885682 0.96169182 0.17667175 0.45620728 0.45203288 0.58498724\n",
      " 0.94616086 0.18390655 0.92714595 0.77719474 0.78268403 0.15553753\n",
      " 0.81662817 0.53413404 0.01593794 0.68316271]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.51885682 0.96169182 0.17667175 0.45620728 0.45203288 0.58498724\n",
      "  0.94616086 0.18390655 0.92714595 0.77719474 0.78268403 0.15553753\n",
      "  0.81662817 0.53413404 0.01593794 0.68316271]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n",
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.78783104 0.45239261 0.37348199 0.79657288 0.71699113 0.6661114\n",
      " 0.46243226 0.88693622 0.75094237 0.18168782 0.68691027 0.62998869\n",
      " 0.31848162 0.63379677 0.1862429  0.22035865]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.78783104 0.45239261 0.37348199 0.79657288 0.71699113 0.6661114\n",
      "  0.46243226 0.88693622 0.75094237 0.18168782 0.68691027 0.62998869\n",
      "  0.31848162 0.63379677 0.1862429  0.22035865]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n",
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.34081911 0.73972345 0.34581446 0.51851666 0.75484433 0.2664358\n",
      " 0.97553542 0.74640234 0.59344518 0.25851942 0.22966061 0.55056486\n",
      " 0.17317834 0.60934657 0.79757954 0.09438307]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.34081911 0.73972345 0.34581446 0.51851666 0.75484433 0.2664358\n",
      "  0.97553542 0.74640234 0.59344518 0.25851942 0.22966061 0.55056486\n",
      "  0.17317834 0.60934657 0.79757954 0.09438307]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n",
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.05180421 0.68830248 0.95930173 0.73724418 0.57034072 0.63539958\n",
      " 0.74847692 0.81939492 0.35552656 0.97440823 0.96498821 0.77574377\n",
      " 0.26305955 0.62802576 0.57302407 0.68383416]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.05180421 0.68830248 0.95930173 0.73724418 0.57034072 0.63539958\n",
      "  0.74847692 0.81939492 0.35552656 0.97440823 0.96498821 0.77574377\n",
      "  0.26305955 0.62802576 0.57302407 0.68383416]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n",
      "INFO:tensorflow:text: this is a toy input\n",
      "INFO:tensorflow:image: [0.24505462 0.92935169 0.84164184 0.98270597 0.66808317 0.82666399\n",
      " 0.61904994 0.21454784 0.43155824 0.67417657 0.55393722 0.62189743\n",
      " 0.72825592 0.99732136 0.99778712 0.65628457]\n",
      "INFO:tensorflow:input_ids: [[101, 8554, 8310, 143, 8228, 8179, 8217, 11300, 102]]\n",
      "INFO:tensorflow:input_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "INFO:tensorflow:segment_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "INFO:tensorflow:toy_cls_label_ids: 0\n",
      "INFO:tensorflow:image_input: [[0.24505462 0.92935169 0.84164184 0.98270597 0.66808317 0.82666399\n",
      "  0.61904994 0.21454784 0.43155824 0.67417657 0.55393722 0.62189743\n",
      "  0.72825592 0.99732136 0.99778712 0.65628457]]\n",
      "INFO:tensorflow:image_mask: [1]\n",
      "INFO:tensorflow:image_segment_ids: [0]\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "preproc_dec_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
