{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp run_bert_multitask\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Bert Multitask Learning\n",
    "\n",
    "Train, eval and predict api for bert multitask learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "from typing import Dict, Callable\n",
    "from shutil import copytree, ignore_patterns, rmtree\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.errors_impl import NotFoundError as TFNotFoundError\n",
    "\n",
    "from bert_multitask_learning.input_fn import predict_input_fn, train_eval_input_fn\n",
    "from bert_multitask_learning.model_fn import BertMultiTask\n",
    "from bert_multitask_learning.params import DynamicBatchSizeParams, BaseParams\n",
    "from bert_multitask_learning.special_tokens import EVAL\n",
    "\n",
    "# Fix duplicate log\n",
    "LOGGER = tf.get_logger()\n",
    "LOGGER.propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def create_keras_model(\n",
    "        mirrored_strategy: tf.distribute.MirroredStrategy,\n",
    "        params: BaseParams,\n",
    "        mode='train',\n",
    "        inputs_to_build_model=None,\n",
    "        model=None):\n",
    "    \"\"\"init model in various mode\n",
    "\n",
    "    train: model will be loaded from huggingface\n",
    "    resume: model will be loaded from params.ckpt_dir, if params.ckpt_dir dose not contain valid checkpoint, then load from huggingface\n",
    "    transfer: model will be loaded from params.init_checkpoint, the correspongding path should contain checkpoints saved using bert-multitask-learning\n",
    "    predict: model will be loaded from params.ckpt_dir except optimizers' states\n",
    "    eval: model will be loaded from params.ckpt_dir except optimizers' states, model will be compiled\n",
    "\n",
    "    Args:\n",
    "        mirrored_strategy (tf.distribute.MirroredStrategy): mirrored strategy\n",
    "        params (BaseParams): params\n",
    "        mode (str, optional): Mode, see above explaination. Defaults to 'train'.\n",
    "        inputs_to_build_model (Dict, optional): A batch of data. Defaults to None.\n",
    "        model (Model, optional): Keras model. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        model: loaded model\n",
    "    \"\"\"\n",
    "   \n",
    "    def _get_model_wrapper(params, mode, inputs_to_build_model, model):\n",
    "        if model is None:\n",
    "            model = BertMultiTask(params)\n",
    "            # model.run_eagerly = True\n",
    "        if mode == 'resume':\n",
    "            model.compile()\n",
    "            # build training graph\n",
    "            # model.train_step(inputs_to_build_model)\n",
    "            _ = model(inputs_to_build_model,\n",
    "                      mode=tf.estimator.ModeKeys.PREDICT)\n",
    "            # load ALL vars including optimizers' states\n",
    "            try:\n",
    "                model.load_weights(os.path.join(\n",
    "                    params.ckpt_dir, 'model'), skip_mismatch=False)\n",
    "            except TFNotFoundError:\n",
    "                LOGGER.warn('Not resuming since no mathcing ckpt found')\n",
    "        elif mode == 'transfer':\n",
    "            # build graph without optimizers' states\n",
    "            # calling compile again should reset optimizers' states but we're playing safe here\n",
    "            _ = model(inputs_to_build_model,\n",
    "                      mode=tf.estimator.ModeKeys.PREDICT)\n",
    "            # load weights without loading optimizers' vars\n",
    "            model.load_weights(os.path.join(params.init_checkpoint, 'model'))\n",
    "            # compile again\n",
    "            model.compile()\n",
    "        elif mode == 'predict':\n",
    "            _ = model(inputs_to_build_model,\n",
    "                      mode=tf.estimator.ModeKeys.PREDICT)\n",
    "            # load weights without loading optimizers' vars\n",
    "            model.load_weights(os.path.join(params.ckpt_dir, 'model'))\n",
    "        elif mode == 'eval':\n",
    "            _ = model(inputs_to_build_model,\n",
    "                      mode=tf.estimator.ModeKeys.PREDICT)\n",
    "            # load weights without loading optimizers' vars\n",
    "            model.load_weights(os.path.join(params.ckpt_dir, 'model'))\n",
    "            model.compile()\n",
    "        else:\n",
    "            model.compile()\n",
    "\n",
    "        return model\n",
    "    if mirrored_strategy is not None:\n",
    "         with mirrored_strategy.scope():\n",
    "             model = _get_model_wrapper(params, mode, inputs_to_build_model, model)\n",
    "    else:\n",
    "        model = _get_model_wrapper(params, mode, inputs_to_build_model, model)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _train_bert_multitask_keras_model(train_dataset: tf.data.Dataset,\n",
    "                                      eval_dataset: tf.data.Dataset,\n",
    "                                      model: tf.keras.Model,\n",
    "                                      params: BaseParams,\n",
    "                                      mirrored_strategy: tf.distribute.MirroredStrategy = None):\n",
    "    # can't save whole model with model subclassing api due to tf bug\n",
    "    # see: https://github.com/tensorflow/tensorflow/issues/42741\n",
    "    # https://github.com/tensorflow/tensorflow/issues/40366\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(params.ckpt_dir, 'model'),\n",
    "        save_weights_only=True,\n",
    "        monitor='val_mean_acc',\n",
    "        mode='auto',\n",
    "        save_best_only=False)\n",
    "\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=params.ckpt_dir)\n",
    "    if mirrored_strategy is not None:\n",
    "        with mirrored_strategy.scope():\n",
    "            model.fit(\n",
    "                x=train_dataset,\n",
    "                validation_data=eval_dataset,\n",
    "                epochs=params.train_epoch,\n",
    "                callbacks=[model_checkpoint_callback, tensorboard_callback],\n",
    "                steps_per_epoch=params.train_steps_per_epoch\n",
    "            )\n",
    "    else:\n",
    "        model.fit(\n",
    "            x=train_dataset,\n",
    "            validation_data=eval_dataset,\n",
    "            epochs=params.train_epoch,\n",
    "            callbacks=[model_checkpoint_callback, tensorboard_callback],\n",
    "            steps_per_epoch=params.train_steps_per_epoch\n",
    "        )\n",
    "    model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_params_ready(problem, num_gpus, model_dir, params, problem_type_dict, processing_fn_dict, mode='train', json_path=''):\n",
    "    if params is None:\n",
    "        params = DynamicBatchSizeParams()\n",
    "    if not os.path.exists('models'):\n",
    "        os.mkdir('models')\n",
    "    if model_dir:\n",
    "        base_dir, dir_name = os.path.split(model_dir)\n",
    "    else:\n",
    "        base_dir, dir_name = None, None\n",
    "    # add new problem to params if problem_type_dict and processing_fn_dict provided\n",
    "    if problem_type_dict:\n",
    "        params.add_multiple_problems(\n",
    "            problem_type_dict=problem_type_dict, processing_fn_dict=processing_fn_dict)\n",
    "    if mode == 'train':\n",
    "        params.assign_problem(problem, gpu=int(num_gpus),\n",
    "                              base_dir=base_dir, dir_name=dir_name)\n",
    "        params.to_json()\n",
    "    else:\n",
    "        params.from_json(json_path)\n",
    "        params.assign_problem(problem, gpu=int(num_gpus),\n",
    "                              base_dir=base_dir, dir_name=dir_name)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def train_bert_multitask(\n",
    "        problem='weibo_ner',\n",
    "        num_gpus=1,\n",
    "        num_epochs=10,\n",
    "        model_dir='',\n",
    "        params: BaseParams = None,\n",
    "        problem_type_dict: Dict[str, str] = None,\n",
    "        processing_fn_dict: Dict[str, Callable] = None,\n",
    "        model: tf.keras.Model = None,\n",
    "        create_tf_record_only=False,\n",
    "        steps_per_epoch=None,\n",
    "        warmup_ratio=0.1,\n",
    "        continue_training=False,\n",
    "        mirrored_strategy=None):\n",
    "    \"\"\"Train Multi-task Bert model\n",
    "\n",
    "    About problem:\n",
    "        There are two types of chaining operations can be used to chain problems.\n",
    "            - `&`. If two problems have the same inputs, they can be chained using `&`.\n",
    "                Problems chained by `&` will be trained at the same time.\n",
    "            - `|`. If two problems don't have the same inputs, they need to be chained using `|`.\n",
    "                Problems chained by `|` will be sampled to train at every instance.\n",
    "\n",
    "        For example, `cws|NER|weibo_ner&weibo_cws`, one problem will be sampled at each turn, say `weibo_ner&weibo_cws`, then `weibo_ner` and `weibo_cws` will trained for this turn together. Therefore, in a particular batch, some tasks might not be sampled, and their loss could be 0 in this batch.\n",
    "\n",
    "    About problem_type_dict and processing_fn_dict:\n",
    "        If the problem is not predefined, you need to tell the model what's the new problem's problem_type\n",
    "        and preprocessing function.\n",
    "            For example, a new problem: fake_classification\n",
    "            problem_type_dict = {'fake_classification': 'cls'}\n",
    "            processing_fn_dict = {'fake_classification': lambda: return ...}\n",
    "\n",
    "        Available problem type:\n",
    "            cls: Classification\n",
    "            seq_tag: Sequence Labeling\n",
    "            seq2seq_tag: Sequence to Sequence tag problem\n",
    "            seq2seq_text: Sequence to Sequence text generation problem\n",
    "\n",
    "        Preprocessing function example:\n",
    "        Please refer to https://github.com/JayYip/bert-multitask-learning/blob/master/README.md\n",
    "\n",
    "    Keyword Arguments:\n",
    "        problem {str} -- Problems to train (default: {'weibo_ner'})\n",
    "        num_gpus {int} -- Number of GPU to use (default: {1})\n",
    "        num_epochs {int} -- Number of epochs to train (default: {10})\n",
    "        model_dir {str} -- model dir (default: {''})\n",
    "        params {BaseParams} -- Params to define training and models (default: {DynamicBatchSizeParams()})\n",
    "        problem_type_dict {dict} -- Key: problem name, value: problem type (default: {{}})\n",
    "        processing_fn_dict {dict} -- Key: problem name, value: problem data preprocessing fn (default: {{}})\n",
    "    \"\"\"\n",
    "    \n",
    "    params = get_params_ready(problem, num_gpus, model_dir,\n",
    "                              params, problem_type_dict, processing_fn_dict)\n",
    "    params.train_epoch = num_epochs\n",
    "\n",
    "    train_dataset = train_eval_input_fn(params)\n",
    "    eval_dataset = train_eval_input_fn(params, mode=EVAL)\n",
    "    if create_tf_record_only:\n",
    "        return\n",
    "\n",
    "    # get train_steps and update params\n",
    "    if steps_per_epoch is not None:\n",
    "        train_steps = steps_per_epoch\n",
    "    else:\n",
    "        train_steps = 0\n",
    "        for _ in train_dataset:\n",
    "            train_steps += 1\n",
    "    params.update_train_steps(train_steps, warmup_ratio=warmup_ratio)\n",
    "    \n",
    "    train_dataset = train_eval_input_fn(params)\n",
    "    train_dataset = train_dataset.repeat(10)\n",
    "\n",
    "    one_batch = next(train_dataset.as_numpy_iterator())\n",
    "\n",
    "    if mirrored_strategy is None:\n",
    "        mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    elif mirrored_strategy is False:\n",
    "        mirrored_strategy = None\n",
    "\n",
    "    if num_gpus > 1 and mirrored_strategy is not False:\n",
    "        train_dataset = mirrored_strategy.experimental_distribute_dataset(\n",
    "            train_dataset)\n",
    "        eval_dataset = mirrored_strategy.experimental_distribute_dataset(\n",
    "            eval_dataset)\n",
    "\n",
    "    # restore priority: self > transfer > huggingface\n",
    "    if continue_training and tf.train.latest_checkpoint(params.ckpt_dir):\n",
    "        mode = 'resume'\n",
    "    elif tf.train.latest_checkpoint(params.init_checkpoint):\n",
    "        mode = 'transfer'\n",
    "    else:\n",
    "        mode = 'train'\n",
    "\n",
    "    model = create_keras_model(\n",
    "        mirrored_strategy=mirrored_strategy, params=params, mode=mode, inputs_to_build_model=one_batch)\n",
    "\n",
    "    _train_bert_multitask_keras_model(\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        model=model,\n",
    "        params=params,\n",
    "        mirrored_strategy=mirrored_strategy\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train multitask\n",
    "\n",
    "Before training, we need to do the following things:\n",
    "- pass transformers corresponding configuration to params, we use `voidful/albert_chinese_tiny` as example here\n",
    "- configure the problems we want to train, which includes\n",
    "    - training problems\n",
    "    - their problem type as a dict\n",
    "    - their preprocessing functions as a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from bert_multitask_learning.predefined_problems import *\n",
    "\n",
    "from bert_multitask_learning import DynamicBatchSizeParams\n",
    "import os\n",
    "from bert_multitask_learning import predict_input_fn\n",
    "params = DynamicBatchSizeParams()\n",
    "params.shuffle_buffer = 1000\n",
    "\n",
    "# configure transformers\n",
    "params.transformer_tokenizer_loading = 'BertTokenizer'\n",
    "params.transformer_model_loading = 'AlbertForMaskedLM'\n",
    "params.transformer_config_loading = 'AlbertConfig'\n",
    "params.transformer_model_name = 'voidful/albert_chinese_tiny'\n",
    "params.transformer_config_name = 'voidful/albert_chinese_tiny'\n",
    "params.transformer_tokenizer_name = 'voidful/albert_chinese_tiny'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import tempfile\n",
    "params.tmp_file_dir = tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "problem = 'weibo_fake_ner&weibo_fake_cls|weibo_fake_multi_cls|weibo_masklm|weibo_pretrain'\n",
    "problem_type_dict = {\n",
    "    'weibo_fake_ner': 'seq_tag',\n",
    "    'weibo_cws': 'seq_tag',\n",
    "    'weibo_fake_multi_cls': 'multi_cls',\n",
    "    'weibo_fake_cls': 'cls',\n",
    "    'weibo_masklm': 'masklm',\n",
    "    'weibo_pretrain': 'pretrain'\n",
    "}\n",
    "\n",
    "processing_fn_dict = {\n",
    "    'weibo_fake_ner': get_weibo_fake_ner_fn(file_path='/data/bert-multitask-learning/data/ner/weiboNER*'),\n",
    "    'weibo_cws': get_weibo_cws_fn(file_path='/data/bert-multitask-learning/data/ner/weiboNER*'),\n",
    "    'weibo_fake_cls': get_weibo_fake_cls_fn(file_path='/data/bert-multitask-learning/data/ner/weiboNER*'),\n",
    "    'weibo_fake_multi_cls': get_weibo_fake_multi_cls_fn(file_path='/data/bert-multitask-learning/data/ner/weiboNER*'),\n",
    "    'weibo_masklm': get_weibo_masklm(file_path='/data/bert-multitask-learning/data/ner/weiboNER*'),\n",
    "    'weibo_pretrain': get_weibo_pretrain_fn(file_path='/data/bert-multitask-learning/data/ner/weiboNER*')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:bert_config not exists. will load model from huggingface checkpoint.\n",
      "404 Client Error: Not Found for url: https://huggingface.co/voidful/albert_chinese_tiny/resolve/main/tf_model.h5\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.dense.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.bias', 'predictions.dense.bias']\n",
      "- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFAlbertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n",
      "WARNING:root:Share embedding is enabled but hidden_size != embedding_size\n",
      "WARNING:root:Share embedding is enabled but hidden_size != embedding_size\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new problem weibo_fake_ner, problem type: seq_tag\n",
      "Adding new problem weibo_cws, problem type: seq_tag\n",
      "Adding new problem weibo_fake_multi_cls, problem type: multi_cls\n",
      "Adding new problem weibo_fake_cls, problem type: cls\n",
      "Adding new problem weibo_masklm, problem type: masklm\n",
      "Adding new problem weibo_pretrain, problem type: pretrain\n",
      "INFO:tensorflow:['科', '技', '全', '方', '位', '资', '讯', '智', '能', '，', '快', '捷', '的', '汽', '车', '生', '活', '需', '要', '有', '三', '屏', '一', '云', '爱', '你']\n",
      "INFO:tensorflow:input_ids: [101, 4906, 2825, 1059, 3175, 855, 6598, 6380, 3255, 5543, 8024, 2571, 2949, 4638, 3749, 6756, 4495, 3833, 7444, 6206, 3300, 676, 2242, 671, 756, 4263, 872, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9]\n",
      "INFO:tensorflow:['对', '，', '输', '给', '一', '个', '女', '人', '，', '的', '成', '绩', '。', '失', '望']\n",
      "INFO:tensorflow:input_ids: [101, 2190, 8024, 6783, 5314, 671, 702, 1957, 782, 8024, 4638, 2768, 5327, 511, 1927, 3307, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9]\n",
      "INFO:tensorflow:['今', '天', '下', '午', '起', '来', '看', '到', '外', '面', '的', '太', '阳', '。', '。', '。', '。', '我', '第', '一', '反', '应', '竟', '然', '是', '强', '烈', '的', '想', '回', '家', '泪', '想', '我', '们', '一', '起', '在', '嘉', '鱼',\n",
      "INFO:tensorflow:input_ids: [101, 791, 1921, 678, 1286, 6629, 3341, 4692, 1168, 1912, 7481, 4638, 1922, 7345, 511, 511, 511, 511, 2769, 5018, 671, 1353, 2418, 4994, 4197, 3221, 2487, 4164, 4638, 2682, 1726, 2157, 3801, 2682, 276\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 5, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 3, 7, 7, 8, 8, 8, 8\n",
      "INFO:tensorflow:['今', '年', '拜', '年', '不', '短', '信', '，', '就', '在', '微', '博', '拜', '大', '年', '寻', '龙', '记']\n",
      "INFO:tensorflow:input_ids: [101, 791, 2399, 2876, 2399, 679, 4764, 928, 8024, 2218, 1762, 2544, 1300, 2876, 1920, 2399, 2192, 7987, 6381, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9]\n",
      "INFO:tensorflow:['浑', '身', '酸', '疼', '，', '两', '腿', '无', '力', '，', '眼', '神', '呆', '滞', '，', '怎', '么', '了']\n",
      "INFO:tensorflow:input_ids: [101, 3847, 6716, 7000, 4563, 8024, 697, 5597, 3187, 1213, 8024, 4706, 4868, 1438, 4005, 8024, 2582, 720, 749, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9]\n",
      "INFO:tensorflow:['明', '显', '紧', '张', '状', '态', '没', '出', '来', '，', '失', '误', '多', '。']\n",
      "INFO:tensorflow:input_ids: [101, 3209, 3227, 5165, 2476, 4307, 2578, 3766, 1139, 3341, 8024, 1927, 6428, 1914, 511, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9]\n",
      "INFO:tensorflow:['三', '十', '年', '前', '，', '老', '爹', '带', '我', '来', '这', '里', '开', '会', '，', '今', '天', '打', '了', '个', '颠', '倒', '。', '我', '在', '这', '里']\n",
      "INFO:tensorflow:input_ids: [101, 676, 1282, 2399, 1184, 8024, 5439, 4269, 2372, 2769, 3341, 6821, 7027, 2458, 833, 8024, 791, 1921, 2802, 749, 702, 7585, 948, 511, 2769, 1762, 6821, 7027, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9]\n",
      "INFO:tensorflow:['好', '活', '动', '呀', '，', '给', '力', '的', '商', '家', '，', '必', '须', '支', '持', '，', '希', '望', '以', '后', '多', '多', '办', '活', '动', '跟', '我', '们', '互', '动', '哈', '巧', '慧', '铣']\n",
      "INFO:tensorflow:input_ids: [101, 1962, 3833, 1220, 1435, 8024, 5314, 1213, 4638, 1555, 2157, 8024, 2553, 7557, 3118, 2898, 8024, 2361, 3307, 809, 1400, 1914, 1914, 1215, 3833, 1220, 6656, 2769, 812, 757, 1220, 1506, 2341, 2716,\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9]\n",
      "INFO:tensorflow:['人', '生', '如', '戏', '，', '导', '演', '是', '自', '己', '蜡', '烛']\n",
      "INFO:tensorflow:input_ids: [101, 782, 4495, 1963, 2767, 8024, 2193, 4028, 3221, 5632, 2346, 6058, 4169, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9]\n",
      "INFO:tensorflow:['听', '说', '小', '米', '开', '卖', '了', '，', '刚', '刚', '预', '约', '了', '台', '。', '我', '爱', '小', '米', '手', '机', '因', '为', '他', '是', '迄', '今', '为', '止', '最', '快', '的', '小', '米', '手', '机', '月', '日', '中', '午',\n",
      "INFO:tensorflow:input_ids: [101, 1420, 6432, 2207, 5101, 2458, 1297, 749, 8024, 1157, 1157, 7564, 5276, 749, 1378, 511, 2769, 4263, 2207, 5101, 2797, 3322, 1728, 711, 800, 3221, 6812, 791, 711, 3632, 3297, 2571, 4638, 2207, 510\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9]\n",
      "INFO:tensorflow:['科', '技', '全', '方', '位', '资', '讯', '智', '能', '，', '快', '捷', '的', '汽', '车', '生', '活', '需', '要', '有', '三', '屏', '一', '云', '爱', '你']\n",
      "INFO:tensorflow:input_ids: [101, 4906, 2825, 1059, 3175, 855, 6598, 6380, 3255, 5543, 8024, 2571, 2949, 4638, 3749, 6756, 4495, 3833, 7444, 6206, 3300, 676, 2242, 671, 756, 4263, 872, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 0\n",
      "INFO:tensorflow:['对', '，', '输', '给', '一', '个', '女', '人', '，', '的', '成', '绩', '。', '失', '望']\n",
      "INFO:tensorflow:input_ids: [101, 2190, 8024, 6783, 5314, 671, 702, 1957, 782, 8024, 4638, 2768, 5327, 511, 1927, 3307, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 0\n",
      "INFO:tensorflow:['今', '天', '下', '午', '起', '来', '看', '到', '外', '面', '的', '太', '阳', '。', '。', '。', '。', '我', '第', '一', '反', '应', '竟', '然', '是', '强', '烈', '的', '想', '回', '家', '泪', '想', '我', '们', '一', '起', '在', '嘉', '鱼',\n",
      "INFO:tensorflow:input_ids: [101, 791, 1921, 678, 1286, 6629, 3341, 4692, 1168, 1912, 7481, 4638, 1922, 7345, 511, 511, 511, 511, 2769, 5018, 671, 1353, 2418, 4994, 4197, 3221, 2487, 4164, 4638, 2682, 1726, 2157, 3801, 2682, 276\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 1\n",
      "INFO:tensorflow:['今', '年', '拜', '年', '不', '短', '信', '，', '就', '在', '微', '博', '拜', '大', '年', '寻', '龙', '记']\n",
      "INFO:tensorflow:input_ids: [101, 791, 2399, 2876, 2399, 679, 4764, 928, 8024, 2218, 1762, 2544, 1300, 2876, 1920, 2399, 2192, 7987, 6381, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 0\n",
      "INFO:tensorflow:['浑', '身', '酸', '疼', '，', '两', '腿', '无', '力', '，', '眼', '神', '呆', '滞', '，', '怎', '么', '了']\n",
      "INFO:tensorflow:input_ids: [101, 3847, 6716, 7000, 4563, 8024, 697, 5597, 3187, 1213, 8024, 4706, 4868, 1438, 4005, 8024, 2582, 720, 749, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 0\n",
      "INFO:tensorflow:['明', '显', '紧', '张', '状', '态', '没', '出', '来', '，', '失', '误', '多', '。']\n",
      "INFO:tensorflow:input_ids: [101, 3209, 3227, 5165, 2476, 4307, 2578, 3766, 1139, 3341, 8024, 1927, 6428, 1914, 511, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 0\n",
      "INFO:tensorflow:['三', '十', '年', '前', '，', '老', '爹', '带', '我', '来', '这', '里', '开', '会', '，', '今', '天', '打', '了', '个', '颠', '倒', '。', '我', '在', '这', '里']\n",
      "INFO:tensorflow:input_ids: [101, 676, 1282, 2399, 1184, 8024, 5439, 4269, 2372, 2769, 3341, 6821, 7027, 2458, 833, 8024, 791, 1921, 2802, 749, 702, 7585, 948, 511, 2769, 1762, 6821, 7027, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 0\n",
      "INFO:tensorflow:['好', '活', '动', '呀', '，', '给', '力', '的', '商', '家', '，', '必', '须', '支', '持', '，', '希', '望', '以', '后', '多', '多', '办', '活', '动', '跟', '我', '们', '互', '动', '哈', '巧', '慧', '铣']\n",
      "INFO:tensorflow:input_ids: [101, 1962, 3833, 1220, 1435, 8024, 5314, 1213, 4638, 1555, 2157, 8024, 2553, 7557, 3118, 2898, 8024, 2361, 3307, 809, 1400, 1914, 1914, 1215, 3833, 1220, 6656, 2769, 812, 757, 1220, 1506, 2341, 2716,\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 0\n",
      "INFO:tensorflow:['人', '生', '如', '戏', '，', '导', '演', '是', '自', '己', '蜡', '烛']\n",
      "INFO:tensorflow:input_ids: [101, 782, 4495, 1963, 2767, 8024, 2193, 4028, 3221, 5632, 2346, 6058, 4169, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 0\n",
      "INFO:tensorflow:['听', '说', '小', '米', '开', '卖', '了', '，', '刚', '刚', '预', '约', '了', '台', '。', '我', '爱', '小', '米', '手', '机', '因', '为', '他', '是', '迄', '今', '为', '止', '最', '快', '的', '小', '米', '手', '机', '月', '日', '中', '午',\n",
      "INFO:tensorflow:input_ids: [101, 1420, 6432, 2207, 5101, 2458, 1297, 749, 8024, 1157, 1157, 7564, 5276, 749, 1378, 511, 2769, 4263, 2207, 5101, 2797, 3322, 1728, 711, 800, 3221, 6812, 791, 711, 3632, 3297, 2571, 4638, 2207, 510\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 0\n",
      "INFO:tensorflow:['一', '节', '课', '的', '时', '间', '真', '心', '感', '动', '了', '李', '开', '复', '感', '动']\n",
      "INFO:tensorflow:input_ids: [101, 671, 5688, 6440, 4638, 3198, 7313, 4696, 2552, 2697, 1220, 749, 3330, 2458, 1908, 2697, 1220, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 3, 7, 7, 8, 8, 9]\n",
      "INFO:tensorflow:['回', '复', '支', '持', '，', '赞', '成', '，', '哈', '哈', '米', '八', '吴', '够', '历', '史', '要', '的', '陈', '小', '奥', '丁', '丁', '我', '爱', '小', '肥', '肥', '一', '族', '大', '头', '仔', '大', '家', '团', '结', '一', '致', '，',\n",
      "INFO:tensorflow:input_ids: [101, 1726, 1908, 3118, 2898, 8024, 6614, 2768, 8024, 1506, 1506, 5101, 1061, 1426, 1916, 1325, 1380, 6206, 4638, 7357, 2207, 1952, 672, 672, 2769, 4263, 2207, 5503, 5503, 671, 3184, 1920, 1928, 798, \n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 3, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 0, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9]\n",
      "INFO:tensorflow:['剑', '网', '乱', '世', '长', '安', '公', '测', '盛', '典', '今', '日', '开', '启', '，', '海', '量', '豪', '礼', '火', '爆', '开', '送', '精', '美', '挂', '件', '、', '听', '雨', '·', '汉', '服', '娃', '娃', '、', '诙', '谐', '双', '骑',\n",
      "INFO:tensorflow:input_ids: [101, 1187, 5381, 744, 686, 7270, 2128, 1062, 3844, 4670, 1073, 791, 3189, 2458, 1423, 8024, 3862, 7030, 6498, 4851, 4125, 4255, 2458, 6843, 5125, 5401, 2899, 816, 510, 1420, 7433, 185, 3727, 3302, 20\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
      "INFO:tensorflow:['在', '街', '上', '听', '见', '音', '乐', '我', '舞', '动', '起', '来', '很', '丢', '人', '？', '真', '的', '很', '丢', '人', '吗', '？']\n",
      "INFO:tensorflow:input_ids: [101, 1762, 6125, 677, 1420, 6224, 7509, 727, 2769, 5659, 1220, 6629, 3341, 2523, 696, 782, 8043, 4696, 4638, 2523, 696, 782, 1408, 8043, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9]\n",
      "INFO:tensorflow:['三', '毛', '说', '我', '唯', '一', '锲', '而', '不', '舍', '，', '愿', '意', '以', '自', '己', '的', '生', '命', '去', '努', '力', '的', '，', '只', '不', '过', '是', '保', '守', '我', '个', '人', '的', '心', '怀', '意', '念', '，', '在',\n",
      "INFO:tensorflow:input_ids: [101, 676, 3688, 6432, 2769, 1546, 671, 7244, 5445, 679, 5650, 8024, 2703, 2692, 809, 5632, 2346, 4638, 4495, 1462, 1343, 1222, 1213, 4638, 8024, 1372, 679, 6814, 3221, 924, 2127, 2769, 702, 782, 4638\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 3, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
      "INFO:tensorflow:['星', '期', '天', '的', '早', '晨', '七', '点', '学', '车', '，', '驾', '校', '太', '给', '力', '。', '我', '的', '头', '发', '都', '没', '有', '洗']\n",
      "INFO:tensorflow:input_ids: [101, 3215, 3309, 1921, 4638, 3193, 3247, 673, 4157, 2110, 6756, 8024, 7730, 3413, 1922, 5314, 1213, 511, 2769, 4638, 1928, 1355, 6963, 3766, 3300, 3819, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9]\n",
      "INFO:tensorflow:['发', '表', '了', '博', '文', '小', '学', '美', '术', '新', '课', '标', '的', '反', '思', '学', '习', '新', '学', '期', '开', '学', '有', '两', '个', '多', '月', '了', '，', '在', '这', '段', '时', '间', '的', '教', '学', '计', '划', '、',\n",
      "INFO:tensorflow:input_ids: [101, 1355, 6134, 749, 1300, 3152, 2207, 2110, 5401, 3318, 3173, 6440, 3403, 4638, 1353, 2590, 2110, 739, 3173, 2110, 3309, 2458, 2110, 3300, 697, 702, 1914, 3299, 749, 8024, 1762, 6821, 3667, 3198, 7\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
      "INFO:tensorflow:['哈', '哈', '哈', '哈', '哈', '哈', '镰', '刀', '刮', '腋', '毛', '哈', '哈', '哈', '哈', '哈', '哈', '我', '的', '朋', '友', '是', '个', '呆', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '十', '万', '个',\n",
      "INFO:tensorflow:input_ids: [101, 1506, 1506, 1506, 1506, 1506, 1506, 7266, 1143, 1167, 5573, 3688, 1506, 1506, 1506, 1506, 1506, 1506, 2769, 4638, 3301, 1351, 3221, 702, 1438, 1506, 1506, 1506, 1506, 1506, 1506, 1506, 1506, 150\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 3\n",
      "INFO:tensorflow:['�', '�', '就', '爱', '这', '个', '牌', '子', '的', '糖', '果']\n",
      "INFO:tensorflow:input_ids: [101, 100, 100, 2218, 4263, 6821, 702, 4277, 2094, 4638, 5131, 3362, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9]\n",
      "INFO:tensorflow:['延', '参', '法', '师', '品', '味', '人', '生', '如', '同', '走', '进', '一', '片', '山', '水', '，', '静', '静', '的', '呼', '吸', '，', '安', '静', '的', '欣', '赏', '，', '这', '就', '是', '生', '活', '。']\n",
      "INFO:tensorflow:input_ids: [101, 2454, 1346, 3791, 2360, 1501, 1456, 782, 4495, 1963, 1398, 6624, 6822, 671, 4275, 2255, 3717, 8024, 7474, 7474, 4638, 1461, 1429, 8024, 2128, 7474, 4638, 3615, 6605, 8024, 6821, 2218, 3221, 4495\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_ner_label_ids: [9, 3, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9]\n",
      "INFO:tensorflow:['一', '节', '课', '的', '时', '间', '真', '心', '感', '动', '了', '李', '开', '复', '感', '动']\n",
      "INFO:tensorflow:input_ids: [101, 671, 5688, 6440, 4638, 3198, 7313, 4696, 2552, 2697, 1220, 749, 3330, 2458, 1908, 2697, 1220, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 1\n",
      "INFO:tensorflow:['回', '复', '支', '持', '，', '赞', '成', '，', '哈', '哈', '米', '八', '吴', '够', '历', '史', '要', '的', '陈', '小', '奥', '丁', '丁', '我', '爱', '小', '肥', '肥', '一', '族', '大', '头', '仔', '大', '家', '团', '结', '一', '致', '，',\n",
      "INFO:tensorflow:input_ids: [101, 1726, 1908, 3118, 2898, 8024, 6614, 2768, 8024, 1506, 1506, 5101, 1061, 1426, 1916, 1325, 1380, 6206, 4638, 7357, 2207, 1952, 672, 672, 2769, 4263, 2207, 5503, 5503, 671, 3184, 1920, 1928, 798, \n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 1\n",
      "INFO:tensorflow:['剑', '网', '乱', '世', '长', '安', '公', '测', '盛', '典', '今', '日', '开', '启', '，', '海', '量', '豪', '礼', '火', '爆', '开', '送', '精', '美', '挂', '件', '、', '听', '雨', '·', '汉', '服', '娃', '娃', '、', '诙', '谐', '双', '骑',\n",
      "INFO:tensorflow:input_ids: [101, 1187, 5381, 744, 686, 7270, 2128, 1062, 3844, 4670, 1073, 791, 3189, 2458, 1423, 8024, 3862, 7030, 6498, 4851, 4125, 4255, 2458, 6843, 5125, 5401, 2899, 816, 510, 1420, 7433, 185, 3727, 3302, 20\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 0\n",
      "INFO:tensorflow:['在', '街', '上', '听', '见', '音', '乐', '我', '舞', '动', '起', '来', '很', '丢', '人', '？', '真', '的', '很', '丢', '人', '吗', '？']\n",
      "INFO:tensorflow:input_ids: [101, 1762, 6125, 677, 1420, 6224, 7509, 727, 2769, 5659, 1220, 6629, 3341, 2523, 696, 782, 8043, 4696, 4638, 2523, 696, 782, 1408, 8043, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 0\n",
      "INFO:tensorflow:['三', '毛', '说', '我', '唯', '一', '锲', '而', '不', '舍', '，', '愿', '意', '以', '自', '己', '的', '生', '命', '去', '努', '力', '的', '，', '只', '不', '过', '是', '保', '守', '我', '个', '人', '的', '心', '怀', '意', '念', '，', '在',\n",
      "INFO:tensorflow:input_ids: [101, 676, 3688, 6432, 2769, 1546, 671, 7244, 5445, 679, 5650, 8024, 2703, 2692, 809, 5632, 2346, 4638, 4495, 1462, 1343, 1222, 1213, 4638, 8024, 1372, 679, 6814, 3221, 924, 2127, 2769, 702, 782, 4638\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 1\n",
      "INFO:tensorflow:['星', '期', '天', '的', '早', '晨', '七', '点', '学', '车', '，', '驾', '校', '太', '给', '力', '。', '我', '的', '头', '发', '都', '没', '有', '洗']\n",
      "INFO:tensorflow:input_ids: [101, 3215, 3309, 1921, 4638, 3193, 3247, 673, 4157, 2110, 6756, 8024, 7730, 3413, 1922, 5314, 1213, 511, 2769, 4638, 1928, 1355, 6963, 3766, 3300, 3819, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 0\n",
      "INFO:tensorflow:['发', '表', '了', '博', '文', '小', '学', '美', '术', '新', '课', '标', '的', '反', '思', '学', '习', '新', '学', '期', '开', '学', '有', '两', '个', '多', '月', '了', '，', '在', '这', '段', '时', '间', '的', '教', '学', '计', '划', '、',\n",
      "INFO:tensorflow:input_ids: [101, 1355, 6134, 749, 1300, 3152, 2207, 2110, 5401, 3318, 3173, 6440, 3403, 4638, 1353, 2590, 2110, 739, 3173, 2110, 3309, 2458, 2110, 3300, 697, 702, 1914, 3299, 749, 8024, 1762, 6821, 3667, 3198, 7\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 0\n",
      "INFO:tensorflow:['哈', '哈', '哈', '哈', '哈', '哈', '镰', '刀', '刮', '腋', '毛', '哈', '哈', '哈', '哈', '哈', '哈', '我', '的', '朋', '友', '是', '个', '呆', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '十', '万', '个',\n",
      "INFO:tensorflow:input_ids: [101, 1506, 1506, 1506, 1506, 1506, 1506, 7266, 1143, 1167, 5573, 3688, 1506, 1506, 1506, 1506, 1506, 1506, 2769, 4638, 3301, 1351, 3221, 702, 1438, 1506, 1506, 1506, 1506, 1506, 1506, 1506, 1506, 150\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 1\n",
      "INFO:tensorflow:['�', '�', '就', '爱', '这', '个', '牌', '子', '的', '糖', '果']\n",
      "INFO:tensorflow:input_ids: [101, 100, 100, 2218, 4263, 6821, 702, 4277, 2094, 4638, 5131, 3362, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 0\n",
      "INFO:tensorflow:['延', '参', '法', '师', '品', '味', '人', '生', '如', '同', '走', '进', '一', '片', '山', '水', '，', '静', '静', '的', '呼', '吸', '，', '安', '静', '的', '欣', '赏', '，', '这', '就', '是', '生', '活', '。']\n",
      "INFO:tensorflow:input_ids: [101, 2454, 1346, 3791, 2360, 1501, 1456, 782, 4495, 1963, 1398, 6624, 6822, 671, 4275, 2255, 3717, 8024, 7474, 7474, 4638, 1461, 1429, 8024, 2128, 7474, 4638, 3615, 6605, 8024, 6821, 2218, 3221, 4495\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_cls_label_ids: 1\n",
      "INFO:tensorflow:text: ['科', '技', '全', '方', '位', '资', '讯', '智', '能', '，', '快', '捷', '的', '汽', '车', '生', '活', '需', '要', '有', '三', '屏', '一', '云', '爱', '你']\n",
      "INFO:tensorflow:image: [[0.11839671 0.38908058 0.55885608 0.66450883 0.68057861 0.97885059\n",
      "  0.8507278  0.14592262 0.43320092 0.22670441]\n",
      " [0.39576809 0.82491846 0.56248869 0.04809291 0.80347845 0.38201267\n",
      "  0.36853199 0.19\n",
      "INFO:tensorflow:input_ids: [101, 4906, 2825, 1059, 3175, 855, 6598, 6380, 3255, 5543, 8024, 2571, 2949, 4638, 3749, 6756, 4495, 3833, 7444, 6206, 3300, 676, 2242, 671, 756, 4263, 872, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.11839671 0.38908058 0.55885608 0.66450883 0.68057861 0.97885059\n",
      "  0.8507278  0.14592262 0.43320092 0.22670441]\n",
      " [0.39576809 0.82491846 0.56248869 0.04809291 0.80347845 0.38201267\n",
      "  0.36853199 0.19\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['对', '，', '输', '给', '一', '个', '女', '人', '，', '的', '成', '绩', '。', '失', '望']\n",
      "INFO:tensorflow:image: [[0.0290981  0.12920171 0.01438529 0.40145449 0.66194236 0.02507522\n",
      "  0.24034556 0.2203874  0.14226219 0.13110174]\n",
      " [0.33948027 0.73614131 0.67191731 0.35970927 0.16378165 0.27031762\n",
      "  0.59172175 0.87\n",
      "INFO:tensorflow:input_ids: [101, 2190, 8024, 6783, 5314, 671, 702, 1957, 782, 8024, 4638, 2768, 5327, 511, 1927, 3307, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.0290981  0.12920171 0.01438529 0.40145449 0.66194236 0.02507522\n",
      "  0.24034556 0.2203874  0.14226219 0.13110174]\n",
      " [0.33948027 0.73614131 0.67191731 0.35970927 0.16378165 0.27031762\n",
      "  0.59172175 0.87\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['今', '天', '下', '午', '起', '来', '看', '到', '外', '面', '的', '太', '阳', '。', '。', '。', '。', '我', '第', '一', '反', '应', '竟', '然', '是', '强', '烈', '的', '想', '回', '家', '泪', '想', '我', '们', '一', '起', '在', '嘉', '鱼',\n",
      "INFO:tensorflow:image: [[0.45948344 0.85810915 0.30581245 0.87875934 0.53335147 0.26575907\n",
      "  0.96358659 0.02390317 0.628901   0.99470142]\n",
      " [0.46759288 0.4315898  0.04835104 0.57163865 0.14403769 0.78242408\n",
      "  0.98920324 0.03\n",
      "INFO:tensorflow:input_ids: [101, 791, 1921, 678, 1286, 6629, 3341, 4692, 1168, 1912, 7481, 4638, 1922, 7345, 511, 511, 511, 511, 2769, 5018, 671, 1353, 2418, 4994, 4197, 3221, 2487, 4164, 4638, 2682, 1726, 2157, 3801, 2682, 276\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.45948344 0.85810915 0.30581245 0.87875934 0.53335147 0.26575907\n",
      "  0.96358659 0.02390317 0.628901   0.99470142]\n",
      " [0.46759288 0.4315898  0.04835104 0.57163865 0.14403769 0.78242408\n",
      "  0.98920324 0.03\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['今', '年', '拜', '年', '不', '短', '信', '，', '就', '在', '微', '博', '拜', '大', '年', '寻', '龙', '记']\n",
      "INFO:tensorflow:image: [[0.87227205 0.61678466 0.81484572 0.50999083 0.46812819 0.26079605\n",
      "  0.46353381 0.56596925 0.62971492 0.21588873]\n",
      " [0.84173484 0.0863188  0.40499977 0.21560345 0.66616591 0.07817273\n",
      "  0.71672657 0.34\n",
      "INFO:tensorflow:input_ids: [101, 791, 2399, 2876, 2399, 679, 4764, 928, 8024, 2218, 1762, 2544, 1300, 2876, 1920, 2399, 2192, 7987, 6381, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.87227205 0.61678466 0.81484572 0.50999083 0.46812819 0.26079605\n",
      "  0.46353381 0.56596925 0.62971492 0.21588873]\n",
      " [0.84173484 0.0863188  0.40499977 0.21560345 0.66616591 0.07817273\n",
      "  0.71672657 0.34\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['浑', '身', '酸', '疼', '，', '两', '腿', '无', '力', '，', '眼', '神', '呆', '滞', '，', '怎', '么', '了']\n",
      "INFO:tensorflow:image: [[0.03243747 0.39924631 0.6419262  0.8651147  0.93102757 0.3807457\n",
      "  0.08476166 0.2014467  0.10358222 0.35956808]\n",
      " [0.79445539 0.80231399 0.83447366 0.60973014 0.12137277 0.38393124\n",
      "  0.31647581 0.192\n",
      "INFO:tensorflow:input_ids: [101, 3847, 6716, 7000, 4563, 8024, 697, 5597, 3187, 1213, 8024, 4706, 4868, 1438, 4005, 8024, 2582, 720, 749, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.03243747 0.39924631 0.6419262  0.8651147  0.93102757 0.3807457\n",
      "  0.08476166 0.2014467  0.10358222 0.35956808]\n",
      " [0.79445539 0.80231399 0.83447366 0.60973014 0.12137277 0.38393124\n",
      "  0.31647581 0.192\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['明', '显', '紧', '张', '状', '态', '没', '出', '来', '，', '失', '误', '多', '。']\n",
      "INFO:tensorflow:image: [[0.59528306 0.28140214 0.24058805 0.17138378 0.75943954 0.17927648\n",
      "  0.37952755 0.25919586 0.3857574  0.65456611]\n",
      " [0.09377965 0.06088413 0.693567   0.10640537 0.27869655 0.8650829\n",
      "  0.12148754 0.325\n",
      "INFO:tensorflow:input_ids: [101, 3209, 3227, 5165, 2476, 4307, 2578, 3766, 1139, 3341, 8024, 1927, 6428, 1914, 511, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.59528306 0.28140214 0.24058805 0.17138378 0.75943954 0.17927648\n",
      "  0.37952755 0.25919586 0.3857574  0.65456611]\n",
      " [0.09377965 0.06088413 0.693567   0.10640537 0.27869655 0.8650829\n",
      "  0.12148754 0.325\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['三', '十', '年', '前', '，', '老', '爹', '带', '我', '来', '这', '里', '开', '会', '，', '今', '天', '打', '了', '个', '颠', '倒', '。', '我', '在', '这', '里']\n",
      "INFO:tensorflow:image: [[0.68565567 0.44173247 0.27298992 0.87809085 0.70659071 0.56289563\n",
      "  0.68740018 0.53143085 0.20102217 0.26760409]\n",
      " [0.93251228 0.11927316 0.96745983 0.84737972 0.78527728 0.43663094\n",
      "  0.38755321 0.10\n",
      "INFO:tensorflow:input_ids: [101, 676, 1282, 2399, 1184, 8024, 5439, 4269, 2372, 2769, 3341, 6821, 7027, 2458, 833, 8024, 791, 1921, 2802, 749, 702, 7585, 948, 511, 2769, 1762, 6821, 7027, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.68565567 0.44173247 0.27298992 0.87809085 0.70659071 0.56289563\n",
      "  0.68740018 0.53143085 0.20102217 0.26760409]\n",
      " [0.93251228 0.11927316 0.96745983 0.84737972 0.78527728 0.43663094\n",
      "  0.38755321 0.10\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['好', '活', '动', '呀', '，', '给', '力', '的', '商', '家', '，', '必', '须', '支', '持', '，', '希', '望', '以', '后', '多', '多', '办', '活', '动', '跟', '我', '们', '互', '动', '哈', '巧', '慧', '铣']\n",
      "INFO:tensorflow:image: [[0.22886702 0.41923109 0.6894823  0.56763948 0.89061875 0.96982842\n",
      "  0.19960945 0.27600959 0.13129816 0.65267778]\n",
      " [0.65296242 0.82187345 0.23907219 0.69922762 0.63803017 0.51068248\n",
      "  0.54259491 0.13\n",
      "INFO:tensorflow:input_ids: [101, 1962, 3833, 1220, 1435, 8024, 5314, 1213, 4638, 1555, 2157, 8024, 2553, 7557, 3118, 2898, 8024, 2361, 3307, 809, 1400, 1914, 1914, 1215, 3833, 1220, 6656, 2769, 812, 757, 1220, 1506, 2341, 2716,\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.22886702 0.41923109 0.6894823  0.56763948 0.89061875 0.96982842\n",
      "  0.19960945 0.27600959 0.13129816 0.65267778]\n",
      " [0.65296242 0.82187345 0.23907219 0.69922762 0.63803017 0.51068248\n",
      "  0.54259491 0.13\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['人', '生', '如', '戏', '，', '导', '演', '是', '自', '己', '蜡', '烛']\n",
      "INFO:tensorflow:image: [[0.143235   0.55356002 0.73985585 0.01275732 0.53043706 0.48283421\n",
      "  0.12480129 0.7672529  0.66146695 0.86617593]\n",
      " [0.13007889 0.10677941 0.99466049 0.07245246 0.25760618 0.9995017\n",
      "  0.37739264 0.265\n",
      "INFO:tensorflow:input_ids: [101, 782, 4495, 1963, 2767, 8024, 2193, 4028, 3221, 5632, 2346, 6058, 4169, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.143235   0.55356002 0.73985585 0.01275732 0.53043706 0.48283421\n",
      "  0.12480129 0.7672529  0.66146695 0.86617593]\n",
      " [0.13007889 0.10677941 0.99466049 0.07245246 0.25760618 0.9995017\n",
      "  0.37739264 0.265\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['听', '说', '小', '米', '开', '卖', '了', '，', '刚', '刚', '预', '约', '了', '台', '。', '我', '爱', '小', '米', '手', '机', '因', '为', '他', '是', '迄', '今', '为', '止', '最', '快', '的', '小', '米', '手', '机', '月', '日', '中', '午',\n",
      "INFO:tensorflow:image: [[4.52224696e-01 2.04634707e-01 8.08728661e-01 2.96637010e-01\n",
      "  2.45797775e-01 8.45124470e-01 7.81012162e-01 7.72991514e-01\n",
      "  3.66281366e-01 6.23355136e-02]\n",
      " [6.59740907e-01 2.05276251e-01 9.43266219e\n",
      "INFO:tensorflow:input_ids: [101, 1420, 6432, 2207, 5101, 2458, 1297, 749, 8024, 1157, 1157, 7564, 5276, 749, 1378, 511, 2769, 4263, 2207, 5101, 2797, 3322, 1728, 711, 800, 3221, 6812, 791, 711, 3632, 3297, 2571, 4638, 2207, 510\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[4.52224696e-01 2.04634707e-01 8.08728661e-01 2.96637010e-01\n",
      "  2.45797775e-01 8.45124470e-01 7.81012162e-01 7.72991514e-01\n",
      "  3.66281366e-01 6.23355136e-02]\n",
      " [6.59740907e-01 2.05276251e-01 9.43266219e\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['一', '节', '课', '的', '时', '间', '真', '心', '感', '动', '了', '李', '开', '复', '感', '动']\n",
      "INFO:tensorflow:image: [[0.89335005 0.01303129 0.03742782 0.36068741 0.81088023 0.28038506\n",
      "  0.01536095 0.92918807 0.70452498 0.22708257]\n",
      " [0.69357423 0.68565221 0.08940999 0.95520647 0.63999168 0.39131101\n",
      "  0.08729312 0.06\n",
      "INFO:tensorflow:input_ids: [101, 671, 5688, 6440, 4638, 3198, 7313, 4696, 2552, 2697, 1220, 749, 3330, 2458, 1908, 2697, 1220, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.89335005 0.01303129 0.03742782 0.36068741 0.81088023 0.28038506\n",
      "  0.01536095 0.92918807 0.70452498 0.22708257]\n",
      " [0.69357423 0.68565221 0.08940999 0.95520647 0.63999168 0.39131101\n",
      "  0.08729312 0.06\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['回', '复', '支', '持', '，', '赞', '成', '，', '哈', '哈', '米', '八', '吴', '够', '历', '史', '要', '的', '陈', '小', '奥', '丁', '丁', '我', '爱', '小', '肥', '肥', '一', '族', '大', '头', '仔', '大', '家', '团', '结', '一', '致', '，',\n",
      "INFO:tensorflow:image: [[0.39002809 0.86223784 0.28332877 0.11460388 0.97433023 0.02981688\n",
      "  0.41265593 0.21542668 0.78993388 0.49216851]\n",
      " [0.17819256 0.47436558 0.85549738 0.71147147 0.11379459 0.29025732\n",
      "  0.89104302 0.34\n",
      "INFO:tensorflow:input_ids: [101, 1726, 1908, 3118, 2898, 8024, 6614, 2768, 8024, 1506, 1506, 5101, 1061, 1426, 1916, 1325, 1380, 6206, 4638, 7357, 2207, 1952, 672, 672, 2769, 4263, 2207, 5503, 5503, 671, 3184, 1920, 1928, 798, \n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.39002809 0.86223784 0.28332877 0.11460388 0.97433023 0.02981688\n",
      "  0.41265593 0.21542668 0.78993388 0.49216851]\n",
      " [0.17819256 0.47436558 0.85549738 0.71147147 0.11379459 0.29025732\n",
      "  0.89104302 0.34\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['剑', '网', '乱', '世', '长', '安', '公', '测', '盛', '典', '今', '日', '开', '启', '，', '海', '量', '豪', '礼', '火', '爆', '开', '送', '精', '美', '挂', '件', '、', '听', '雨', '·', '汉', '服', '娃', '娃', '、', '诙', '谐', '双', '骑',\n",
      "INFO:tensorflow:image: [[0.14591517 0.42523246 0.77893337 0.13097386 0.75692106 0.9051706\n",
      "  0.31496374 0.8179107  0.05355553 0.53599328]\n",
      " [0.33193516 0.62031345 0.81480689 0.43488613 0.25839695 0.13352649\n",
      "  0.51079824 0.715\n",
      "INFO:tensorflow:input_ids: [101, 1187, 5381, 744, 686, 7270, 2128, 1062, 3844, 4670, 1073, 791, 3189, 2458, 1423, 8024, 3862, 7030, 6498, 4851, 4125, 4255, 2458, 6843, 5125, 5401, 2899, 816, 510, 1420, 7433, 185, 3727, 3302, 20\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.14591517 0.42523246 0.77893337 0.13097386 0.75692106 0.9051706\n",
      "  0.31496374 0.8179107  0.05355553 0.53599328]\n",
      " [0.33193516 0.62031345 0.81480689 0.43488613 0.25839695 0.13352649\n",
      "  0.51079824 0.715\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['在', '街', '上', '听', '见', '音', '乐', '我', '舞', '动', '起', '来', '很', '丢', '人', '？', '真', '的', '很', '丢', '人', '吗', '？']\n",
      "INFO:tensorflow:image: [[0.67543162 0.77605228 0.88743768 0.10257804 0.46054449 0.37288511\n",
      "  0.27737097 0.35075594 0.71174699 0.47144439]\n",
      " [0.20488533 0.57864943 0.73403603 0.39983254 0.47757517 0.84589138\n",
      "  0.65844631 0.98\n",
      "INFO:tensorflow:input_ids: [101, 1762, 6125, 677, 1420, 6224, 7509, 727, 2769, 5659, 1220, 6629, 3341, 2523, 696, 782, 8043, 4696, 4638, 2523, 696, 782, 1408, 8043, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.67543162 0.77605228 0.88743768 0.10257804 0.46054449 0.37288511\n",
      "  0.27737097 0.35075594 0.71174699 0.47144439]\n",
      " [0.20488533 0.57864943 0.73403603 0.39983254 0.47757517 0.84589138\n",
      "  0.65844631 0.98\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['三', '毛', '说', '我', '唯', '一', '锲', '而', '不', '舍', '，', '愿', '意', '以', '自', '己', '的', '生', '命', '去', '努', '力', '的', '，', '只', '不', '过', '是', '保', '守', '我', '个', '人', '的', '心', '怀', '意', '念', '，', '在',\n",
      "INFO:tensorflow:image: [[0.33821083 0.19800479 0.45124224 0.51513995 0.4565659  0.58463903\n",
      "  0.45542931 0.00427128 0.00108334 0.42402044]\n",
      " [0.75894244 0.94322679 0.70124331 0.29218934 0.77249919 0.15993162\n",
      "  0.88464009 0.48\n",
      "INFO:tensorflow:input_ids: [101, 676, 3688, 6432, 2769, 1546, 671, 7244, 5445, 679, 5650, 8024, 2703, 2692, 809, 5632, 2346, 4638, 4495, 1462, 1343, 1222, 1213, 4638, 8024, 1372, 679, 6814, 3221, 924, 2127, 2769, 702, 782, 4638\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.33821083 0.19800479 0.45124224 0.51513995 0.4565659  0.58463903\n",
      "  0.45542931 0.00427128 0.00108334 0.42402044]\n",
      " [0.75894244 0.94322679 0.70124331 0.29218934 0.77249919 0.15993162\n",
      "  0.88464009 0.48\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['星', '期', '天', '的', '早', '晨', '七', '点', '学', '车', '，', '驾', '校', '太', '给', '力', '。', '我', '的', '头', '发', '都', '没', '有', '洗']\n",
      "INFO:tensorflow:image: [[0.35461633 0.46626101 0.58695873 0.5226616  0.74391829 0.09944663\n",
      "  0.80998224 0.5269131  0.37222788 0.80263236]\n",
      " [0.66781529 0.69907562 0.82037631 0.89338457 0.83228863 0.39824228\n",
      "  0.41623066 0.33\n",
      "INFO:tensorflow:input_ids: [101, 3215, 3309, 1921, 4638, 3193, 3247, 673, 4157, 2110, 6756, 8024, 7730, 3413, 1922, 5314, 1213, 511, 2769, 4638, 1928, 1355, 6963, 3766, 3300, 3819, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.35461633 0.46626101 0.58695873 0.5226616  0.74391829 0.09944663\n",
      "  0.80998224 0.5269131  0.37222788 0.80263236]\n",
      " [0.66781529 0.69907562 0.82037631 0.89338457 0.83228863 0.39824228\n",
      "  0.41623066 0.33\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['发', '表', '了', '博', '文', '小', '学', '美', '术', '新', '课', '标', '的', '反', '思', '学', '习', '新', '学', '期', '开', '学', '有', '两', '个', '多', '月', '了', '，', '在', '这', '段', '时', '间', '的', '教', '学', '计', '划', '、',\n",
      "INFO:tensorflow:image: [[0.57428139 0.06725755 0.87219895 0.15060786 0.05234578 0.91322898\n",
      "  0.67693773 0.75470339 0.40814118 0.29803347]\n",
      " [0.528401   0.48067335 0.71069224 0.9081367  0.19938285 0.82941759\n",
      "  0.41227859 0.05\n",
      "INFO:tensorflow:input_ids: [101, 1355, 6134, 749, 1300, 3152, 2207, 2110, 5401, 3318, 3173, 6440, 3403, 4638, 1353, 2590, 2110, 739, 3173, 2110, 3309, 2458, 2110, 3300, 697, 702, 1914, 3299, 749, 8024, 1762, 6821, 3667, 3198, 7\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.57428139 0.06725755 0.87219895 0.15060786 0.05234578 0.91322898\n",
      "  0.67693773 0.75470339 0.40814118 0.29803347]\n",
      " [0.528401   0.48067335 0.71069224 0.9081367  0.19938285 0.82941759\n",
      "  0.41227859 0.05\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['哈', '哈', '哈', '哈', '哈', '哈', '镰', '刀', '刮', '腋', '毛', '哈', '哈', '哈', '哈', '哈', '哈', '我', '的', '朋', '友', '是', '个', '呆', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '十', '万', '个',\n",
      "INFO:tensorflow:image: [[0.51630432 0.92757931 0.55461666 0.29926045 0.17288608 0.29105192\n",
      "  0.71790218 0.84809544 0.54476038 0.64763123]\n",
      " [0.14068756 0.69292868 0.12335598 0.66724893 0.64498822 0.52106412\n",
      "  0.45717906 0.32\n",
      "INFO:tensorflow:input_ids: [101, 1506, 1506, 1506, 1506, 1506, 1506, 7266, 1143, 1167, 5573, 3688, 1506, 1506, 1506, 1506, 1506, 1506, 2769, 4638, 3301, 1351, 3221, 702, 1438, 1506, 1506, 1506, 1506, 1506, 1506, 1506, 1506, 150\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.51630432 0.92757931 0.55461666 0.29926045 0.17288608 0.29105192\n",
      "  0.71790218 0.84809544 0.54476038 0.64763123]\n",
      " [0.14068756 0.69292868 0.12335598 0.66724893 0.64498822 0.52106412\n",
      "  0.45717906 0.32\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['�', '�', '就', '爱', '这', '个', '牌', '子', '的', '糖', '果']\n",
      "INFO:tensorflow:image: [[0.26960882 0.19119714 0.15593626 0.88161872 0.51353123 0.704504\n",
      "  0.64149475 0.15300241 0.15525688 0.52860923]\n",
      " [0.29995126 0.89639462 0.07592154 0.60581238 0.31075755 0.60197236\n",
      "  0.92893744 0.5038\n",
      "INFO:tensorflow:input_ids: [101, 100, 100, 2218, 4263, 6821, 702, 4277, 2094, 4638, 5131, 3362, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.26960882 0.19119714 0.15593626 0.88161872 0.51353123 0.704504\n",
      "  0.64149475 0.15300241 0.15525688 0.52860923]\n",
      " [0.29995126 0.89639462 0.07592154 0.60581238 0.31075755 0.60197236\n",
      "  0.92893744 0.5038\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:text: ['延', '参', '法', '师', '品', '味', '人', '生', '如', '同', '走', '进', '一', '片', '山', '水', '，', '静', '静', '的', '呼', '吸', '，', '安', '静', '的', '欣', '赏', '，', '这', '就', '是', '生', '活', '。']\n",
      "INFO:tensorflow:image: [[0.79204552 0.86678824 0.61041029 0.85120837 0.41150536 0.18160503\n",
      "  0.58336111 0.61275485 0.61632532 0.76458168]\n",
      " [0.07683201 0.91684841 0.24311687 0.16691909 0.63957982 0.51239092\n",
      "  0.5487883  0.46\n",
      "INFO:tensorflow:input_ids: [101, 2454, 1346, 3791, 2360, 1501, 1456, 782, 4495, 1963, 1398, 6624, 6822, 671, 4275, 2255, 3717, 8024, 7474, 7474, 4638, 1461, 1429, 8024, 2128, 7474, 4638, 3615, 6605, 8024, 6821, 2218, 3221, 4495\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:weibo_fake_multi_cls_label_ids: [1 1 1]\n",
      "INFO:tensorflow:image_input: [[0.79204552 0.86678824 0.61041029 0.85120837 0.41150536 0.18160503\n",
      "  0.58336111 0.61275485 0.61632532 0.76458168]\n",
      " [0.07683201 0.91684841 0.24311687 0.16691909 0.63957982 0.51239092\n",
      "  0.5487883  0.46\n",
      "INFO:tensorflow:image_mask: [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:image_segment_ids: [0 0 0 0 0]\n",
      "INFO:tensorflow:['对', '，', '输', '给', '一', '个', '女', '人', '，', '的', '成', '绩', '。', '失', '望']\n",
      "INFO:tensorflow:input_ids: [101, 2190, 8024, 6783, 5314, 671, 702, 1957, 782, 103, 4638, 103, 5327, 511, 1927, 103, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_positions: [9, 11, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [8024 2768 3307    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['今', '天', '下', '午', '起', '来', '看', '到', '外', '面', '的', '太', '阳', '。', '。', '。', '。', '我', '第', '一', '反', '应', '竟', '然', '是', '强', '烈', '的', '想', '回', '家', '泪', '想', '我', '们', '一', '起', '在', '嘉', '鱼',\n",
      "INFO:tensorflow:input_ids: [101, 791, 1921, 678, 103, 6629, 3341, 4692, 1168, 1912, 7481, 4638, 1922, 7345, 103, 511, 511, 511, 2769, 103, 103, 1353, 2418, 4994, 103, 103, 103, 4164, 4638, 2682, 1726, 103, 3801, 2682, 2769, 103\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:masked_lm_positions: [4, 14, 19, 20, 24, 25, 26, 31, 35, 46, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [1286  511 5018  671 4197 3221 2487 2157  812  511    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['今', '年', '拜', '年', '不', '短', '信', '，', '就', '在', '微', '博', '拜', '大', '年', '寻', '龙', '记']\n",
      "INFO:tensorflow:input_ids: [101, 103, 2399, 2876, 103, 679, 4764, 928, 8024, 2218, 1762, 103, 1300, 103, 1920, 2399, 2192, 7987, 6381, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_positions: [1, 4, 11, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [ 791 2399 2544 2876    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['浑', '身', '酸', '疼', '，', '两', '腿', '无', '力', '，', '眼', '神', '呆', '滞', '，', '怎', '么', '了']\n",
      "INFO:tensorflow:input_ids: [101, 3847, 6716, 7000, 4563, 8024, 697, 5597, 3187, 103, 8024, 4706, 4868, 1438, 103, 8024, 2582, 103, 749, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_positions: [9, 14, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [1213 4005  720    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['明', '显', '紧', '张', '状', '态', '没', '出', '来', '，', '失', '误', '多', '。']\n",
      "INFO:tensorflow:input_ids: [101, 3209, 3227, 5165, 2476, 103, 2578, 103, 1139, 3341, 8024, 1927, 6428, 1914, 511, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_positions: [5, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [4307 3766    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['三', '十', '年', '前', '，', '老', '爹', '带', '我', '来', '这', '里', '开', '会', '，', '今', '天', '打', '了', '个', '颠', '倒', '。', '我', '在', '这', '里']\n",
      "INFO:tensorflow:input_ids: [101, 676, 1282, 2399, 103, 8024, 5439, 4269, 2372, 103, 3341, 6821, 7027, 2458, 833, 8024, 791, 1921, 103, 103, 702, 103, 948, 511, 2769, 1762, 6821, 7027, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_positions: [4, 9, 18, 19, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [1184 2769 2802  749 7585    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['好', '活', '动', '呀', '，', '给', '力', '的', '商', '家', '，', '必', '须', '支', '持', '，', '希', '望', '以', '后', '多', '多', '办', '活', '动', '跟', '我', '们', '互', '动', '哈', '巧', '慧', '铣']\n",
      "INFO:tensorflow:input_ids: [101, 1962, 3833, 103, 1435, 8024, 5314, 103, 4638, 1555, 2157, 8024, 2553, 7557, 3118, 2898, 8024, 2361, 103, 809, 103, 1914, 1914, 1215, 3833, 1220, 6656, 2769, 812, 757, 1220, 103, 103, 103, 7203, \n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_positions: [3, 7, 18, 20, 31, 32, 33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [1220 1213 3307 1400 1506 2341 2716    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['人', '生', '如', '戏', '，', '导', '演', '是', '自', '己', '蜡', '烛']\n",
      "INFO:tensorflow:input_ids: [101, 103, 4495, 1963, 2767, 8024, 2193, 4028, 3221, 5632, 103, 6058, 4169, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_positions: [1, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [ 782 2346    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['听', '说', '小', '米', '开', '卖', '了', '，', '刚', '刚', '预', '约', '了', '台', '。', '我', '爱', '小', '米', '手', '机', '因', '为', '他', '是', '迄', '今', '为', '止', '最', '快', '的', '小', '米', '手', '机', '月', '日', '中', '午',\n",
      "INFO:tensorflow:input_ids: [101, 1420, 6432, 2207, 5101, 2458, 1297, 103, 8024, 1157, 1157, 7564, 5276, 749, 1378, 511, 2769, 4263, 2207, 5101, 2797, 3322, 1728, 711, 800, 3221, 6812, 791, 711, 3632, 3297, 2571, 4638, 2207, 103\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_positions: [7, 34, 51, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [ 749 5101 2207 5276    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['最', '热', '时', '尚', '榜', '女', '人', '不', '坏', '，', '男', '人', '不', '爱', '，', '一', '个', '男', '女', '必', '看', '的', '微', '博', '花', '心']\n",
      "INFO:tensorflow:input_ids: [101, 3297, 4178, 3198, 2213, 103, 1957, 782, 679, 1776, 103, 4511, 782, 679, 4263, 8024, 103, 702, 4511, 103, 2553, 4692, 4638, 2544, 1300, 5709, 2552, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_positions: [5, 10, 16, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [3528 8024  671 1957    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['回', '复', '支', '持', '，', '赞', '成', '，', '哈', '哈', '米', '八', '吴', '够', '历', '史', '要', '的', '陈', '小', '奥', '丁', '丁', '我', '爱', '小', '肥', '肥', '一', '族', '大', '头', '仔', '大', '家', '团', '结', '一', '致', '，',\n",
      "INFO:tensorflow:input_ids: [101, 1726, 1908, 3118, 2898, 8024, 6614, 2768, 8024, 1506, 1506, 103, 1061, 1426, 1916, 1325, 1380, 103, 103, 7357, 2207, 1952, 672, 672, 2769, 4263, 2207, 103, 5503, 671, 3184, 1920, 1928, 798, 1920\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_positions: [11, 17, 18, 27, 46, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [5101 6206 4638 5503 7650    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['剑', '网', '乱', '世', '长', '安', '公', '测', '盛', '典', '今', '日', '开', '启', '，', '海', '量', '豪', '礼', '火', '爆', '开', '送', '精', '美', '挂', '件', '、', '听', '雨', '·', '汉', '服', '娃', '娃', '、', '诙', '谐', '双', '骑',\n",
      "INFO:tensorflow:input_ids: [101, 1187, 5381, 744, 103, 7270, 2128, 1062, 3844, 4670, 1073, 791, 3189, 2458, 103, 103, 3862, 7030, 6498, 4851, 4125, 4255, 2458, 103, 5125, 5401, 103, 816, 510, 103, 7433, 185, 3727, 103, 2015, 20\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:masked_lm_positions: [4, 14, 15, 23, 26, 29, 33, 39, 62, 64, 66, 80, 87, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [ 686 1423 8024 6843 2899 1420 3302 1352 2661 6760 1315 2135 2787    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['在', '街', '上', '听', '见', '音', '乐', '我', '舞', '动', '起', '来', '很', '丢', '人', '？', '真', '的', '很', '丢', '人', '吗', '？']\n",
      "INFO:tensorflow:input_ids: [101, 1762, 103, 103, 1420, 6224, 7509, 727, 2769, 5659, 1220, 6629, 103, 2523, 103, 782, 8043, 4696, 4638, 2523, 103, 782, 1408, 8043, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_positions: [2, 3, 12, 14, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [6125  677 3341  696  696    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['三', '毛', '说', '我', '唯', '一', '锲', '而', '不', '舍', '，', '愿', '意', '以', '自', '己', '的', '生', '命', '去', '努', '力', '的', '，', '只', '不', '过', '是', '保', '守', '我', '个', '人', '的', '心', '怀', '意', '念', '，', '在',\n",
      "INFO:tensorflow:input_ids: [101, 676, 3688, 6432, 2769, 1546, 671, 7244, 5445, 679, 5650, 8024, 2703, 2692, 103, 5632, 2346, 4638, 4495, 1462, 1343, 1222, 1213, 4638, 103, 1372, 679, 6814, 103, 924, 2127, 2769, 702, 782, 103, 2\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:masked_lm_positions: [14, 24, 28, 34, 42, 44, 58, 64, 68, 69, 71, 73, 77, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [ 809 8024 3221 4638 3300  722 2190 1469 1762 3300 4638 4958 3187    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['星', '期', '天', '的', '早', '晨', '七', '点', '学', '车', '，', '驾', '校', '太', '给', '力', '。', '我', '的', '头', '发', '都', '没', '有', '洗']\n",
      "INFO:tensorflow:input_ids: [101, 3215, 3309, 1921, 4638, 3193, 3247, 673, 4157, 2110, 6756, 8024, 7730, 3413, 1922, 103, 1213, 511, 2769, 4638, 1928, 1355, 6963, 103, 3300, 3819, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_positions: [15, 23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [5314 3766    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['发', '表', '了', '博', '文', '小', '学', '美', '术', '新', '课', '标', '的', '反', '思', '学', '习', '新', '学', '期', '开', '学', '有', '两', '个', '多', '月', '了', '，', '在', '这', '段', '时', '间', '的', '教', '学', '计', '划', '、',\n",
      "INFO:tensorflow:input_ids: [101, 1355, 6134, 749, 103, 3152, 2207, 2110, 5401, 3318, 3173, 6440, 3403, 4638, 1353, 2590, 2110, 739, 3173, 2110, 3309, 2458, 2110, 3300, 697, 702, 1914, 3299, 749, 103, 1762, 6821, 3667, 3198, 103\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:masked_lm_positions: [4, 29, 34, 60, 62, 76, 78, 86, 89, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [1300 8024 7313 3403 3300 4500 3136 4415  809    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['哈', '哈', '哈', '哈', '哈', '哈', '镰', '刀', '刮', '腋', '毛', '哈', '哈', '哈', '哈', '哈', '哈', '我', '的', '朋', '友', '是', '个', '呆', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '哈', '十', '万', '个',\n",
      "INFO:tensorflow:input_ids: [101, 1506, 1506, 1506, 1506, 1506, 1506, 7266, 1143, 1167, 5573, 3688, 1506, 1506, 103, 1506, 1506, 1506, 2769, 4638, 3301, 1351, 3221, 702, 1438, 1506, 1506, 1506, 1506, 1506, 1506, 103, 1506, 1506,\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "INFO:tensorflow:masked_lm_positions: [14, 31, 54, 71, 72, 89, 91, 97, 98, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [1506 1506 1506 1506 1506 1506 1506 3392 7448 1506    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['�', '�', '就', '爱', '这', '个', '牌', '子', '的', '糖', '果']\n",
      "INFO:tensorflow:input_ids: [101, 2218, 4263, 6821, 702, 4277, 2094, 4638, 5131, 103, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_positions: [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [3362    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['延', '参', '法', '师', '品', '味', '人', '生', '如', '同', '走', '进', '一', '片', '山', '水', '，', '静', '静', '的', '呼', '吸', '，', '安', '静', '的', '欣', '赏', '，', '这', '就', '是', '生', '活', '。']\n",
      "INFO:tensorflow:input_ids: [101, 103, 1346, 3791, 2360, 1501, 1456, 782, 103, 1963, 1398, 6624, 6822, 103, 4275, 2255, 3717, 8024, 7474, 7474, 4638, 1461, 1429, 8024, 2128, 103, 4638, 3615, 6605, 8024, 6821, 2218, 103, 4495, 10\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_positions: [1, 8, 13, 25, 32, 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [2454 4495  671 7474 3221 3833    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:['就', '感', '恩', '吧', '越', '来', '越', '没', '战', '斗', '力', '了', '。']\n",
      "INFO:tensorflow:input_ids: [101, 103, 2697, 2617, 1416, 6632, 3341, 6632, 3766, 2773, 103, 1213, 749, 511, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_positions: [1, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:masked_lm_ids: [2218 3159    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "INFO:tensorflow:masked_lm_weights: [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "INFO:tensorflow:sampling weights: \n",
      "INFO:tensorflow:weibo_fake_cls_weibo_fake_ner: 0.4\n",
      "INFO:tensorflow:weibo_fake_multi_cls: 0.2\n",
      "INFO:tensorflow:weibo_masklm: 0.2\n",
      "INFO:tensorflow:weibo_pretrain: 0.2\n",
      "INFO:tensorflow:sampling weights: \n",
      "INFO:tensorflow:weibo_fake_cls_weibo_fake_ner: 0.4\n",
      "INFO:tensorflow:weibo_fake_multi_cls: 0.2\n",
      "INFO:tensorflow:weibo_masklm: 0.2\n",
      "INFO:tensorflow:weibo_pretrain: 0.2\n",
      "INFO:tensorflow:sampling weights: \n",
      "INFO:tensorflow:weibo_fake_cls_weibo_fake_ner: 0.4\n",
      "INFO:tensorflow:weibo_fake_multi_cls: 0.2\n",
      "INFO:tensorflow:weibo_masklm: 0.2\n",
      "INFO:tensorflow:weibo_pretrain: 0.2\n",
      "WARNING:tensorflow:From /data/anaconda3/lib/python3.8/inspect.py:350: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /data/anaconda3/lib/python3.8/inspect.py:350: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Initial lr: 2e-05\n",
      "INFO:tensorflow:Train steps: 1\n",
      "INFO:tensorflow:Warmup steps: 0\n",
      "WARNING:tensorflow:Seems there's a multimodal inputs but params.enable_modal_type is not set to be True.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function BertMultiTaskBody.get_features_for_problem at 0x7f9a77238040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:Seems there's a multimodal inputs but params.enable_modal_type is not set to be True.\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f9b245f92e0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f9b245f92e0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Seems there's a multimodal inputs but params.enable_modal_type is not set to be True.\n",
      "1/1 [==============================] - ETA: 0s - mean_acc: 0.8462 - weibo_fake_cls_acc: 1.0000 - weibo_fake_ner_acc: 0.6923 - weibo_fake_ner_loss: 1.3234 - weibo_fake_cls_loss: 0.0814 - weibo_fake_multi_cls_loss: 0.5802 - weibo_masklm_loss: 0.0000e+00 - weibo_pretrain_loss: 10.7076WARNING:tensorflow:Seems there's a multimodal inputs but params.enable_modal_type is not set to be True.\n",
      "1/1 [==============================] - 8s 8s/step - mean_acc: 0.8462 - weibo_fake_cls_acc: 1.0000 - weibo_fake_ner_acc: 0.6923 - weibo_fake_ner_loss: 1.3234 - weibo_fake_cls_loss: 0.0814 - weibo_fake_multi_cls_loss: 0.5802 - weibo_masklm_loss: 0.0000e+00 - weibo_pretrain_loss: 10.7076 - val_loss: 16.5235 - val_mean_acc: 0.5994 - val_weibo_fake_cls_acc: 0.4500 - val_weibo_fake_ner_acc: 0.6309\n",
      "Model: \"BertMultiTask\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "BertMultiTaskBody (BertMulti multiple                  4081928   \n",
      "_________________________________________________________________\n",
      "BertMultiTaskTop (BertMultiT multiple                  13231453  \n",
      "_________________________________________________________________\n",
      "mean_acc (Mean)              multiple                  2         \n",
      "=================================================================\n",
      "Total params: 17,313,383\n",
      "Trainable params: 17,313,377\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = train_bert_multitask(\n",
    "    problem=problem,\n",
    "    num_epochs=1,\n",
    "    params=params,\n",
    "    problem_type_dict=problem_type_dict,\n",
    "    processing_fn_dict=processing_fn_dict,\n",
    "    steps_per_epoch=1,\n",
    "    continue_training=True,\n",
    "    mirrored_strategy=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_bert_multitask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c6050be31e8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# hide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model = train_bert_multitask(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mproblem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_bert_multitask' is not defined"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "model = train_bert_multitask(\n",
    "    problem=problem,\n",
    "    num_epochs=1,\n",
    "    params=params,\n",
    "    problem_type_dict=problem_type_dict,\n",
    "    processing_fn_dict=processing_fn_dict,\n",
    "    continue_training=True\n",
    ")\n",
    "\n",
    "# fresh train\n",
    "_ = train_bert_multitask(\n",
    "    problem=problem,\n",
    "    num_epochs=1,\n",
    "    params=params,\n",
    "    problem_type_dict=problem_type_dict,\n",
    "    processing_fn_dict=processing_fn_dict,\n",
    "    steps_per_epoch=1,\n",
    "    continue_training=False,\n",
    "    mirrored_strategy=False,\n",
    "    model_dir='./models/fresh_train'\n",
    ")\n",
    "\n",
    "# transfer train\n",
    "params.init_checkpoint = './models/fresh_train'\n",
    "_ = train_bert_multitask(\n",
    "    problem=problem,\n",
    "    num_epochs=1,\n",
    "    params=params,\n",
    "    problem_type_dict=problem_type_dict,\n",
    "    processing_fn_dict=processing_fn_dict,\n",
    "    steps_per_epoch=1,\n",
    "    continue_training=False,\n",
    "    mirrored_strategy=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def trim_checkpoint_for_prediction(problem: str,\n",
    "                                   input_dir: str,\n",
    "                                   output_dir: str,\n",
    "                                   problem_type_dict: Dict[str, str] = None,\n",
    "                                   overwrite=True,\n",
    "                                   fake_input_list=None,\n",
    "                                   params=None):\n",
    "    \"\"\"Minimize checkpoint size for prediction.\n",
    "\n",
    "    Since the original checkpoint contains optimizer's variable,\n",
    "        for instance, if the use adam, the checkpoint size will \n",
    "        be three times of the size of model weights. This function \n",
    "        will remove those unused variables in prediction to save space.\n",
    "\n",
    "    Note: if the model is a multimodal model, you have to provide fake_input_list that\n",
    "        mimic the structure of real input.\n",
    "\n",
    "    Args:\n",
    "        problem (str): problem\n",
    "        input_dir (str): input dir\n",
    "        output_dir (str): output dir\n",
    "        problem_type_dict (Dict[str, str], optional): problem type dict. Defaults to None.\n",
    "        fake_input_list (List): fake input list to create dummy dataset\n",
    "    \"\"\"\n",
    "    if overwrite and os.path.exists(output_dir):\n",
    "        rmtree(output_dir)\n",
    "    copytree(input_dir, output_dir, ignore=ignore_patterns(\n",
    "        'checkpoint', '*.index', '*.data-000*'))\n",
    "    base_dir, dir_name = os.path.split(output_dir)\n",
    "    if params is None:\n",
    "        params = DynamicBatchSizeParams()\n",
    "    params.add_multiple_problems(problem_type_dict=problem_type_dict)\n",
    "    params.from_json(os.path.join(input_dir, 'params.json'))\n",
    "    params.assign_problem(problem, base_dir=base_dir,\n",
    "                          dir_name=dir_name, predicting=True)\n",
    "\n",
    "    model = BertMultiTask(params)\n",
    "    if fake_input_list is None:\n",
    "        dummy_dataset = predict_input_fn(['fake']*5, params)\n",
    "    else:\n",
    "        dummy_dataset = predict_input_fn(fake_input_list*5, params)\n",
    "    _ = model(next(dummy_dataset.as_numpy_iterator()),\n",
    "              mode=tf.estimator.ModeKeys.PREDICT)\n",
    "    model.load_weights(os.path.join(input_dir, 'model'))\n",
    "    model.save_weights(os.path.join(params.ckpt_dir, 'model'))\n",
    "    params.to_json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim checkpoints\n",
    "\n",
    "The checkpoints contains optimizers' states which is not needed once training is done and it makes the checkpoint size two times larger. We provide an api to trim down the size of checkpoint by removing optimizers' states.\n",
    "\n",
    "Note: in multimodal setting, you need to provide a fake input to build the model correctly. Otherwise modal embeddings will be randomly initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new problem weibo_fake_ner, problem type: seq_tag\n",
      "Adding new problem weibo_cws, problem type: seq_tag\n",
      "Adding new problem weibo_fake_multi_cls, problem type: multi_cls\n",
      "Adding new problem weibo_fake_cls, problem type: cls\n",
      "Adding new problem weibo_masklm, problem type: masklm\n",
      "Adding new problem weibo_pretrain, problem type: pretrain\n",
      "WARNING:root:Share embedding is enabled but hidden_size != embedding_size\n",
      "WARNING:root:Share embedding is enabled but hidden_size != embedding_size\n"
     ]
    }
   ],
   "source": [
    "# fake inputs\n",
    "import numpy as np\n",
    "fake_inputs = [{'text': 'test', 'image': np.random.uniform(\n",
    "            size=(5, 10))} for _ in range(5)] \n",
    "trim_checkpoint_for_prediction(\n",
    "    problem=problem, input_dir=model.params.ckpt_dir,\n",
    "    output_dir=model.params.ckpt_dir+'_pred',\n",
    "    problem_type_dict=problem_type_dict, overwrite=True, fake_input_list=fake_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def eval_bert_multitask(\n",
    "        problem='weibo_ner',\n",
    "        num_gpus=1,\n",
    "        model_dir='',\n",
    "        params=None,\n",
    "        problem_type_dict=None,\n",
    "        processing_fn_dict=None,\n",
    "        model=None):\n",
    "    \"\"\"Evaluate Multi-task Bert model\n",
    "\n",
    "    Available eval_scheme:\n",
    "        ner, cws, acc\n",
    "\n",
    "    Keyword Arguments:\n",
    "        problem {str} -- problems to evaluate (default: {'weibo_ner'})\n",
    "        num_gpus {int} -- number of gpu to use (default: {1})\n",
    "        model_dir {str} -- model dir (default: {''})\n",
    "        eval_scheme {str} -- Evaluation scheme (default: {'ner'})\n",
    "        params {Params} -- params to define model (default: {DynamicBatchSizeParams()})\n",
    "        problem_type_dict {dict} -- Key: problem name, value: problem type (default: {{}})\n",
    "        processing_fn_dict {dict} -- Key: problem name, value: problem data preprocessing fn (default: {{}})\n",
    "    \"\"\"\n",
    "    if not model_dir and params is not None:\n",
    "        model_dir = params.ckpt_dir\n",
    "    params = get_params_ready(problem, num_gpus, model_dir,\n",
    "                              params, problem_type_dict, processing_fn_dict,\n",
    "                              mode='predict', json_path=os.path.join(model_dir, 'params.json'))\n",
    "    eval_dataset = train_eval_input_fn(params, mode=EVAL)\n",
    "    one_batch_data = next(eval_dataset.as_numpy_iterator())\n",
    "    eval_dataset = train_eval_input_fn(params, mode=EVAL)\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    model = create_keras_model(\n",
    "        mirrored_strategy=mirrored_strategy, params=params, mode='eval', inputs_to_build_model=one_batch_data)\n",
    "    eval_dict = model.evaluate(eval_dataset, return_dict=True)\n",
    "    return eval_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval\n",
    "\n",
    "Now we can use the trimmed checkpoint to do evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new problem weibo_fake_ner, problem type: seq_tag\n",
      "Adding new problem weibo_cws, problem type: seq_tag\n",
      "Adding new problem weibo_fake_multi_cls, problem type: multi_cls\n",
      "Adding new problem weibo_fake_cls, problem type: cls\n",
      "Adding new problem weibo_masklm, problem type: masklm\n",
      "Adding new problem weibo_pretrain, problem type: pretrain\n",
      "WARNING:root:Share embedding is enabled but hidden_size != embedding_size\n",
      "WARNING:root:Share embedding is enabled but hidden_size != embedding_size\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "9/9 [==============================] - 3s 329ms/step - loss: 16.5940 - mean_acc: 0.6559 - weibo_fake_cls_acc: 0.6000 - weibo_fake_ner_acc: 0.6994\n",
      "Adding new problem weibo_fake_ner, problem type: seq_tag\n",
      "Adding new problem weibo_cws, problem type: seq_tag\n",
      "Adding new problem weibo_fake_multi_cls, problem type: multi_cls\n",
      "Adding new problem weibo_fake_cls, problem type: cls\n",
      "Adding new problem weibo_masklm, problem type: masklm\n",
      "Adding new problem weibo_pretrain, problem type: pretrain\n",
      "WARNING:root:Share embedding is enabled but hidden_size != embedding_size\n",
      "WARNING:root:Share embedding is enabled but hidden_size != embedding_size\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "9/9 [==============================] - 3s 344ms/step - loss: 16.5940 - mean_acc: 0.6559 - weibo_fake_cls_acc: 0.6000 - weibo_fake_ner_acc: 0.6994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 16.59403419494629,\n",
       " 'mean_acc': 0.6558765769004822,\n",
       " 'weibo_fake_cls_acc': 0.6000000238418579,\n",
       " 'weibo_fake_ner_acc': 0.699386477470398}"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_bert_multitask(problem=problem, params=params,\n",
    "                    problem_type_dict=problem_type_dict, processing_fn_dict=processing_fn_dict,\n",
    "                    model_dir=model.params.ckpt_dir+'_pred')\n",
    "\n",
    "# provide model instead of dir\n",
    "eval_bert_multitask(problem=problem, params=params,\n",
    "                    problem_type_dict=problem_type_dict, processing_fn_dict=processing_fn_dict,\n",
    "                    model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def predict_bert_multitask(\n",
    "        inputs,\n",
    "        problem='weibo_ner',\n",
    "        model_dir='',\n",
    "        params: BaseParams = None,\n",
    "        problem_type_dict: Dict[str, str] = None,\n",
    "        processing_fn_dict: Dict[str, Callable] = None,\n",
    "        model: tf.keras.Model = None,\n",
    "        return_model=False):\n",
    "    \"\"\"Evaluate Multi-task Bert model\n",
    "\n",
    "    Available eval_scheme:\n",
    "        ner, cws, acc\n",
    "\n",
    "    Keyword Arguments:\n",
    "        problem {str} -- problems to evaluate (default: {'weibo_ner'})\n",
    "        num_gpus {int} -- number of gpu to use (default: {1})\n",
    "        model_dir {str} -- model dir (default: {''})\n",
    "        eval_scheme {str} -- Evaluation scheme (default: {'ner'})\n",
    "        params {Params} -- params to define model (default: {DynamicBatchSizeParams()})\n",
    "        problem_type_dict {dict} -- Key: problem name, value: problem type (default: {{}})\n",
    "        processing_fn_dict {dict} -- Key: problem name, value: problem data preprocessing fn (default: {{}})\n",
    "    \"\"\"\n",
    "\n",
    "    if params is None:\n",
    "        params = DynamicBatchSizeParams()\n",
    "    if not model_dir and params is not None:\n",
    "        model_dir = params.ckpt_dir\n",
    "    params = get_params_ready(problem, 1, model_dir,\n",
    "                              params, problem_type_dict, processing_fn_dict,\n",
    "                              mode='predict', json_path=os.path.join(model_dir, 'params.json'))\n",
    "\n",
    "    LOGGER.info('Checkpoint dir: %s', params.ckpt_dir)\n",
    "    time.sleep(3)\n",
    "\n",
    "    pred_dataset = predict_input_fn(inputs, params)\n",
    "    one_batch_data = next(pred_dataset.as_numpy_iterator())\n",
    "    pred_dataset = predict_input_fn(inputs, params)\n",
    "\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    if model is None:\n",
    "        model = create_keras_model(\n",
    "            mirrored_strategy=mirrored_strategy, params=params, mode='predict', inputs_to_build_model=one_batch_data)\n",
    "\n",
    "    with mirrored_strategy.scope():\n",
    "        pred = model.predict(pred_dataset)\n",
    "\n",
    "    if return_model:\n",
    "        return pred, model\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "We can do prediction by providing list of input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new problem weibo_fake_ner, problem type: seq_tag\n",
      "Adding new problem weibo_cws, problem type: seq_tag\n",
      "Adding new problem weibo_fake_multi_cls, problem type: multi_cls\n",
      "Adding new problem weibo_fake_cls, problem type: cls\n",
      "Adding new problem weibo_masklm, problem type: masklm\n",
      "Adding new problem weibo_pretrain, problem type: pretrain\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "pred, model = predict_bert_multitask(\n",
    "    problem='weibo_fake_ner',\n",
    "    inputs=fake_inputs*20, model_dir=model.params.ckpt_dir,\n",
    "    problem_type_dict=problem_type_dict,\n",
    "    processing_fn_dict=processing_fn_dict, return_model=True,\n",
    "    params=params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
