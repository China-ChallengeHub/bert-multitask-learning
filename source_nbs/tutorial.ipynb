{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "In this tutorial, we'll start with the most basic example to get you up and running the model as quickly and easily as possible. Then we'll dive into some more complicated example and hopefully you'll get some insight of what happened behind the scene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal Example\n",
    "\n",
    "In this example, we'll create train, eval and predict toy problems. But first, we need to what dose problem mean here. Essentially, a problem should have **a name(string), a problem type(string), and a preprocessing function(callable)**. The following problem type is pre-defined:\n",
    "\n",
    "- `cls`: classification\n",
    "- `seq_tag`: sequence labeling\n",
    "- `multi_cls`: multi-label classification\n",
    "- `mask_lm`: masked language model\n",
    "- `pretrain`: masked lm + next sentence prediction\n",
    "\n",
    "Normally, you would want to use this library to do multi-task learning. There are two types of chaining operations can be used to chain problems.\n",
    "\n",
    "- `&`. If two problems have the same inputs, they can be chained using `&`. Problems chained by `&` will be trained at the same time.\n",
    "- `|`. If two problems don't have the same inputs, they need to be chained using `|`. Problems chained by `|` will be sampled to train at every instance.\n",
    "\n",
    "If your problem dose not fall in the pre-defined problem types, you can implement your own and register to params. We will cover this topic later. Let's start with a simple example of adding a classification problem and a sequence labeling problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define toy problems name and problem type\n",
    "problem_type_dict = {'toy_cls': 'cls', 'toy_seq_tag': 'seq_tag'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to do some coding. We need to implement preprocessing function for each problem. The preprocessing function is a callable with \n",
    "\n",
    "- same name as problem name\n",
    "- fixed input signature \n",
    "- returns(or yield) inputs and targets\n",
    "- decorated by `bert_multitask_learning.preproc_decorator.preprocessing_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple preprocessing function\n",
    "import bert_multitask_learning\n",
    "from bert_multitask_learning.preproc_decorator import preprocessing_fn\n",
    "from bert_multitask_learning.params import BaseParams\n",
    "@preprocessing_fn\n",
    "def toy_cls(params: BaseParams, mode: str):\n",
    "    \"Simple example to demonstrate singe modal tuple of list return\"\n",
    "    if mode == bert_multitask_learning.TRAIN:\n",
    "        toy_input = ['this is a test' for _ in range(10)]\n",
    "        toy_target = ['a' if i <=5 else 'b' for i in range(10)]\n",
    "    else:\n",
    "        toy_input = ['this is a test' for _ in range(10)]\n",
    "        toy_target = ['a' if i <=5 else 'b' for i in range(10)]\n",
    "    return toy_input, toy_target\n",
    "\n",
    "@preprocessing_fn\n",
    "def toy_seq_tag(params: BaseParams, mode: str):\n",
    "    \"Simple example to demonstrate singe modal tuple of list return\"\n",
    "    if mode == bert_multitask_learning.TRAIN:\n",
    "        toy_input = ['this is a test'.split(' ') for _ in range(10)]\n",
    "        toy_target = [['a', 'b', 'c', 'd'] for _ in range(10)]\n",
    "    else:\n",
    "        toy_input = ['this is a test'.split(' ') for _ in range(10)]\n",
    "        toy_target = [['a', 'b', 'c', 'd'] for _ in range(10)]\n",
    "    return toy_input, toy_target\n",
    "\n",
    "processing_fn_dict = {'toy_cls': toy_cls, 'toy_seq_tag': toy_seq_tag}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're good to go! Since these two toy problems shares the same input, we can chain them with `&`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:bert_config not exists. will load model from huggingface checkpoint.\n",
      "Adding new problem toy_cls, problem type: cls\n",
      "Adding new problem toy_seq_tag, problem type: seq_tag\n",
      "INFO:tensorflow:sampling weights: \n",
      "INFO:tensorflow:toy_cls_toy_seq_tag: 1.0\n",
      "INFO:tensorflow:sampling weights: \n",
      "INFO:tensorflow:toy_cls_toy_seq_tag: 1.0\n",
      "INFO:tensorflow:sampling weights: \n",
      "INFO:tensorflow:toy_cls_toy_seq_tag: 1.0\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Some layers from the model checkpoint at bert-base-chinese were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-chinese.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "WARNING:tensorflow:From /data/anaconda3/lib/python3.8/inspect.py:350: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /data/anaconda3/lib/python3.8/inspect.py:350: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Initial lr: 2e-05\n",
      "INFO:tensorflow:Train steps: 1\n",
      "INFO:tensorflow:Warmup steps: 0\n",
      "WARNING:tensorflow:From /data/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f071c6a6940>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f071c6a6940>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "1/1 [==============================] - ETA: 0s - mean_acc: 0.3000 - toy_cls_acc: 0.3000 - toy_seq_tag_acc: 0.3000 - toy_cls_loss: 0.8341 - toy_seq_tag_loss: 2.0840The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "1/1 [==============================] - 7s 7s/step - mean_acc: 0.3000 - toy_cls_acc: 0.3000 - toy_seq_tag_acc: 0.3000 - toy_cls_loss: 0.8341 - toy_seq_tag_loss: 2.0840 - val_loss: 2.7318 - val_mean_acc: 0.3833 - val_toy_cls_acc: 0.6000 - val_toy_seq_tag_acc: 0.1667\n",
      "Model: \"BertMultiTask\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "BertMultiTaskBody (BertMulti multiple                  102267648 \n",
      "_________________________________________________________________\n",
      "BertMultiTaskTop (BertMultiT multiple                  5387      \n",
      "_________________________________________________________________\n",
      "mean_acc (Mean)              multiple                  2         \n",
      "=================================================================\n",
      "Total params: 102,273,037\n",
      "Trainable params: 102,273,031\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# collapse_output\n",
    "from bert_multitask_learning import train_bert_multitask, eval_bert_multitask, predict_bert_multitask\n",
    "problem = 'toy_cls&toy_seq_tag'\n",
    "# train\n",
    "model = train_bert_multitask(\n",
    "    problem=problem,\n",
    "    num_epochs=1,\n",
    "    problem_type_dict=problem_type_dict,\n",
    "    processing_fn_dict=processing_fn_dict,\n",
    "    continue_training=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For eval, we can need to provide `model_dir` or `model` to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "esolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.1.attention.self_attention.query.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.1.attention.self_attention.query.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.1.attention.self_attention.key.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.1.attention.self_attention.key.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.1.attention.self_attention.value.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.1.attention.self_attention.value.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.1.attention.dense_output.dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.1.attention.dense_output.dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.1.attention.dense_output.LayerNorm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.1.attention.dense_output.LayerNorm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.2.attention.self_attention.query.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.2.attention.self_attention.query.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.2.attention.self_attention.key.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.2.attention.self_attention.key.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.2.attention.self_attention.value.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.2.attention.self_attention.value.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.2.attention.dense_output.dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.2.attention.dense_output.dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.2.attention.dense_output.LayerNorm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.2.attention.dense_output.LayerNorm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.3.attention.self_attention.query.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.3.attention.self_attention.query.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.3.attention.self_attention.key.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.3.attention.self_attention.key.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.3.attention.self_attention.value.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.3.attention.self_attention.value.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.3.attention.dense_output.dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.3.attention.dense_output.dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.3.attention.dense_output.LayerNorm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.3.attention.dense_output.LayerNorm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.4.attention.self_attention.query.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.4.attention.self_attention.query.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.4.attention.self_attention.key.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.4.attention.self_attention.key.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.4.attention.self_attention.value.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.4.attention.self_attention.value.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.4.attention.dense_output.dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.4.attention.dense_output.dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.4.attention.dense_output.LayerNorm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.4.attention.dense_output.LayerNorm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.5.attention.self_attention.query.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.5.attention.self_attention.query.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.5.attention.self_attention.key.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.5.attention.self_attention.key.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.5.attention.self_attention.value.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.5.attention.self_attention.value.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.5.attention.dense_output.dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.5.attention.dense_output.dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.5.attention.dense_output.LayerNorm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.5.attention.dense_output.LayerNorm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.6.attention.self_attention.query.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.6.attention.self_attention.query.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.6.attention.self_attention.key.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.6.attention.self_attention.key.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.6.attention.self_attention.value.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.6.attention.self_attention.value.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.6.attention.dense_output.dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.6.attention.dense_output.dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.6.attention.dense_output.LayerNorm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.6.attention.dense_output.LayerNorm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.7.attention.self_attention.query.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.7.attention.self_attention.query.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.7.attention.self_attention.key.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.7.attention.self_attention.key.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.7.attention.self_attention.value.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.7.attention.self_attention.value.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.7.attention.dense_output.dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.7.attention.dense_output.dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.7.attention.dense_output.LayerNorm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.7.attention.dense_output.LayerNorm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.8.attention.self_attention.query.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.8.attention.self_attention.query.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.8.attention.self_attention.key.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.8.attention.self_attention.key.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.8.attention.self_attention.value.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.8.attention.self_attention.value.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.8.attention.dense_output.dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.8.attention.dense_output.dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.8.attention.dense_output.LayerNorm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.8.attention.dense_output.LayerNorm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.9.attention.self_attention.query.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.9.attention.self_attention.query.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.9.attention.self_attention.key.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.9.attention.self_attention.key.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.9.attention.self_attention.value.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.9.attention.self_attention.value.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.9.attention.dense_output.dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.9.attention.dense_output.dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.9.attention.dense_output.LayerNorm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.9.attention.dense_output.LayerNorm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.10.attention.self_attention.query.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.10.attention.self_attention.query.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.10.attention.self_attention.key.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.10.attention.self_attention.key.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.10.attention.self_attention.value.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.10.attention.self_attention.value.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.10.attention.dense_output.dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.10.attention.dense_output.dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.10.attention.dense_output.LayerNorm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.10.attention.dense_output.LayerNorm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.11.attention.self_attention.query.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.11.attention.self_attention.query.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.11.attention.self_attention.key.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.11.attention.self_attention.key.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.11.attention.self_attention.value.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.11.attention.self_attention.value.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.11.attention.dense_output.dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.11.attention.dense_output.dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.11.attention.dense_output.LayerNorm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.bert.encoder.layer.11.attention.dense_output.LayerNorm.beta\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.7318 - mean_acc: 0.3833 - toy_cls_acc: 0.6000 - toy_seq_tag_acc: 0.1667\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "# eval\n",
    "eval_dict = eval_bert_multitask(problem=problem,\n",
    "                    problem_type_dict=problem_type_dict, processing_fn_dict=processing_fn_dict,\n",
    "                    model_dir=model.params.ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7317519187927246, 'mean_acc': 0.38333335518836975, 'toy_cls_acc': 0.6000000238418579, 'toy_seq_tag_acc': 0.1666666716337204}\n"
     ]
    }
   ],
   "source": [
    "print(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:bert_config not exists. will load model from huggingface checkpoint.\n",
      "Adding new problem toy_cls, problem type: cls\n",
      "Adding new problem toy_seq_tag, problem type: seq_tag\n",
      "INFO:tensorflow:Checkpoint dir: models/toy_cls_toy_seq_tag_ckpt\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Some layers from the model checkpoint at bert-base-chinese were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-chinese.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:['this', 'is', 'a', 'test']\n",
      "INFO:tensorflow:input_ids: [101, 8554, 8310, 143, 10060, 102]\n",
      "INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "# predict\n",
    "fake_inputs = ['this is a test'.split(' ') for _ in range(10)]\n",
    "pred, model = predict_bert_multitask(\n",
    "    problem=problem,\n",
    "    inputs=fake_inputs, model_dir=model.params.ckpt_dir,\n",
    "    problem_type_dict=problem_type_dict,\n",
    "    processing_fn_dict=processing_fn_dict, return_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pred` is a dictionary with problem name as key and probability distribution array as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toy_cls - (10, 2)\ntoy_seq_tag - (10, 6, 5)\n"
     ]
    }
   ],
   "source": [
    "for problem_name, prob_array in pred.items():\n",
    "    print(f'{problem_name} - {prob_array.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Different Models\n",
    "\n",
    "By default, we use Bert as the base model. But thanks to transformers, it's easy to switch to any SOTA transformers models with some simple configuration and pass the params to train function as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).body.bert.bert_model.distilbert.transformer.layer.5.ffn.lin1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).body.bert.bert_model.distilbert.transformer.layer.5.ffn.lin1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).body.bert.bert_model.distilbert.transformer.layer.5.ffn.lin2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).body.bert.bert_model.distilbert.transformer.layer.5.ffn.lin2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.embeddings.word_embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.embeddings.position_embeddings.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.embeddings.LayerNorm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.embeddings.LayerNorm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.0.sa_layer_norm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.0.sa_layer_norm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.0.output_layer_norm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.0.output_layer_norm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.1.sa_layer_norm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.1.sa_layer_norm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.1.output_layer_norm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.1.output_layer_norm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.2.sa_layer_norm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.2.sa_layer_norm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.2.output_layer_norm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.2.output_layer_norm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.3.sa_layer_norm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.3.sa_layer_norm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.3.output_layer_norm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.3.output_layer_norm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.4.sa_layer_norm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.4.sa_layer_norm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.4.output_layer_norm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.4.output_layer_norm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.5.sa_layer_norm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.5.sa_layer_norm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.5.output_layer_norm.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.5.output_layer_norm.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.0.attention.q_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.0.attention.q_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.0.attention.k_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.0.attention.k_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.0.attention.v_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.0.attention.v_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.0.attention.out_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.0.attention.out_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.0.ffn.lin1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.0.ffn.lin1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.0.ffn.lin2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.0.ffn.lin2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.1.attention.q_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.1.attention.q_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.1.attention.k_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.1.attention.k_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.1.attention.v_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.1.attention.v_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.1.attention.out_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.1.attention.out_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.1.ffn.lin1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.1.ffn.lin1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.1.ffn.lin2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.1.ffn.lin2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.2.attention.q_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.2.attention.q_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.2.attention.k_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.2.attention.k_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.2.attention.v_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.2.attention.v_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.2.attention.out_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.2.attention.out_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.2.ffn.lin1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.2.ffn.lin1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.2.ffn.lin2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.2.ffn.lin2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.3.attention.q_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.3.attention.q_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.3.attention.k_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.3.attention.k_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.3.attention.v_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.3.attention.v_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.3.attention.out_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.3.attention.out_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.3.ffn.lin1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.3.ffn.lin1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.3.ffn.lin2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.3.ffn.lin2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.4.attention.q_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.4.attention.q_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.4.attention.k_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.4.attention.k_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.4.attention.v_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.4.attention.v_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.4.attention.out_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.4.attention.out_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.4.ffn.lin1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.4.ffn.lin1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.4.ffn.lin2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.4.ffn.lin2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.5.attention.q_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.5.attention.q_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.5.attention.k_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.5.attention.k_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.5.attention.v_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.5.attention.v_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.5.attention.out_lin.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.5.attention.out_lin.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.5.ffn.lin1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.5.ffn.lin1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.5.ffn.lin2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).body.bert.bert_model.distilbert.transformer.layer.5.ffn.lin2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "1/1 [==============================] - ETA: 0s - mean_acc: 0.4250 - toy_cls_acc: 0.6000 - toy_seq_tag_acc: 0.2500 - toy_cls_loss: 0.7036 - toy_seq_tag_loss: 1.6635The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "1/1 [==============================] - 5s 5s/step - mean_acc: 0.4250 - toy_cls_acc: 0.6000 - toy_seq_tag_acc: 0.2500 - toy_cls_loss: 0.7036 - toy_seq_tag_loss: 1.6635 - val_loss: 2.3481 - val_mean_acc: 0.3833 - val_toy_cls_acc: 0.6000 - val_toy_seq_tag_acc: 0.1667\n",
      "Model: \"BertMultiTask\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "BertMultiTaskBody (BertMulti multiple                  66362880  \n",
      "_________________________________________________________________\n",
      "BertMultiTaskTop (BertMultiT multiple                  5387      \n",
      "_________________________________________________________________\n",
      "mean_acc (Mean)              multiple                  2         \n",
      "=================================================================\n",
      "Total params: 66,368,269\n",
      "Trainable params: 66,368,263\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "# change model to distilbert-base-uncased\n",
    "from bert_multitask_learning.params import BaseParams\n",
    "params = BaseParams()\n",
    "# specify model and its loading module\n",
    "params.transformer_model_name = 'distilbert-base-uncased'\n",
    "params.transformer_model_loading = 'TFDistilBertModel'\n",
    "# specify tokenizer and its loading module\n",
    "params.transformer_tokenizer_name = 'distilbert-base-uncased'\n",
    "params.transformer_tokenizer_loading = 'DistilBertTokenizer'\n",
    "# specify config and its loading module\n",
    "params.transformer_config_name = 'distilbert-base-uncased'\n",
    "params.transformer_config_loading = 'DistilBertConfig'\n",
    "\n",
    "# train model\n",
    "model = train_bert_multitask(\n",
    "    problem=problem,\n",
    "    num_epochs=1,\n",
    "    problem_type_dict=problem_type_dict,\n",
    "    processing_fn_dict=processing_fn_dict,\n",
    "    continue_training=True,\n",
    "    params=params # pass params\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write More Flexible Preprocessing Function\n",
    "\n",
    "The preprocessing function should return two elements: inputs and targets, except for `pretrain` problem type. You don't need to manually tokenize your inputs and encode the targets, it will be done automatically.\n",
    "\n",
    "For features and targets, it can be one of the following format:\n",
    "- tuple of list. This is the way to go if your data can fit into memory.\n",
    "- generator of tuple. You should use generator if your data cannot fit into memory.\n",
    "\n",
    "The features can be single modal and multi-modal. We will elaborate each form of the input in this section.\n",
    "\n",
    "Please note that if preprocessing function returns generator of tuple, then corresponding problem cannot be chained using `&`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Modal Input\n",
    "\n",
    "#### Tuple of list\n",
    "\n",
    "Normal text, label pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessing_fn\n",
    "def toy_cls(params: BaseParams, mode: str):\n",
    "    \"Simple example to demonstrate singe modal tuple of list return\"\n",
    "    if mode == bert_multitask_learning.TRAIN:\n",
    "        toy_input = ['this is a test' for _ in range(10)]\n",
    "        toy_target = ['a' if i <=5 else 'b' for i in range(10)]\n",
    "    else:\n",
    "        toy_input = ['this is a test' for _ in range(10)]\n",
    "        toy_target = ['a' if i <=5 else 'b' for i in range(10)]\n",
    "    return toy_input, toy_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A, B tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessing_fn\n",
    "def toy_cls(params: BaseParams, mode: str):\n",
    "    \"Simple example to demonstrate singe modal tuple of list return\"\n",
    "    if mode == bert_multitask_learning.TRAIN:\n",
    "        toy_input = [{'a': 'this is a test', 'b': 'this is a test'} for _ in range(10)]\n",
    "        toy_target = ['a' if i <=5 else 'b' for i in range(10)]\n",
    "    else:\n",
    "        toy_input = [{'a': 'this is a test', 'b': 'this is a test'} for _ in range(10)]\n",
    "        toy_target = ['a' if i <=5 else 'b' for i in range(10)]\n",
    "    return toy_input, toy_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator of tuple\n",
    "\n",
    "Normal text, label pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessing_fn\n",
    "def toy_cls(params: BaseParams, mode: str):\n",
    "    \"Simple example to demonstrate singe modal tuple of list return\"\n",
    "    if mode == bert_multitask_learning.TRAIN:\n",
    "        toy_input = ['this is a test' for _ in range(10)]\n",
    "        toy_target = ['a' if i <=5 else 'b' for i in range(10)]\n",
    "    else:\n",
    "        toy_input = ['this is a test' for _ in range(10)]\n",
    "        toy_target = ['a' if i <=5 else 'b' for i in range(10)]\n",
    "    for single_input, single_target in zip(toy_input, toy_target):\n",
    "        yield single_input, single_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A, B tokens. Same, skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-modal Input\n",
    "\n",
    "The other modal should be passed as an array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuple of list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessing_fn\n",
    "def toy_cls(params: BaseParams, mode: str):\n",
    "    \"Simple example to demonstrate multi-modal tuple of list return\"\n",
    "    if mode == bert_multitask_learning.TRAIN:\n",
    "        toy_input = [{'text': 'this is a test', 'image': np.random.uniform(size=(16))} for _ in range(10)]\n",
    "        toy_target = ['a' if i <=5 else 'b' for i in range(10)]\n",
    "    else:\n",
    "        toy_input = [{'text': 'this is a test', 'image': np.random.uniform(size=(16))} for _ in range(10)]\n",
    "        toy_target = ['a' if i <=5 else 'b' for i in range(10)]\n",
    "    \n",
    "    return toy_input, toy_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator of tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessing_fn\n",
    "def toy_cls(params: BaseParams, mode: str):\n",
    "    \"Simple example to demonstrate multi-modal tuple of list return\"\n",
    "    if mode == bert_multitask_learning.TRAIN:\n",
    "        toy_input = [{'text': 'this is a test', 'image': np.random.uniform(size=(16))} for _ in range(10)]\n",
    "        toy_target = ['a' if i <=5 else 'b' for i in range(10)]\n",
    "    else:\n",
    "        toy_input = [{'text': 'this is a test', 'image': np.random.uniform(size=(16))} for _ in range(10)]\n",
    "        toy_target = ['a' if i <=5 else 'b' for i in range(10)]\n",
    "    \n",
    "    for single_input, single_target in zip(toy_input, toy_target):\n",
    "        yield single_input, single_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: A, B token of multi-modal input is not working yet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Happened?\n",
    "\n",
    "The inputs returned by preprocessing function will be tokenized using transformers tokenizer which is configurable like we showed before and the labels will be encoded(or tokenized if the target is text) as scalar or numpy array. The encoded inputs and target then will be serialized and written as TFRecord. Please note that the TFRecord will NOT be overwritten even if you run the code again. So if you want to change the data in TFRecord, you need to manually remove the directory of TFRecord. The default directory is `./tmp/{problem_name}`.\n",
    "\n",
    "After the TFRecord is created, if you want to check the feature info, you can head to the corresponding directory and take a look at the json file within. \n",
    "\n",
    "First, we make sure the TFRecord is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:sampling weights: \n",
      "INFO:tensorflow:toy_cls_toy_seq_tag: 1.0\n"
     ]
    }
   ],
   "source": [
    "# train_eval_input_fn will create and read the TFRecord, and returns a dataset\n",
    "from bert_multitask_learning.input_fn import train_eval_input_fn\n",
    "\n",
    "dataset = train_eval_input_fn(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n    \"input_ids\": \"int64\",\n    \"input_ids_shape_value\": [\n        null\n    ],\n    \"input_ids_shape\": \"int64\",\n    \"input_mask\": \"int64\",\n    \"input_mask_shape_value\": [\n        null\n    ],\n    \"input_mask_shape\": \"int64\",\n    \"segment_ids\": \"int64\",\n    \"segment_ids_shape_value\": [\n        null\n    ],\n    \"segment_ids_shape\": \"int64\",\n    \"toy_cls_label_ids\": \"int64\",\n    \"toy_cls_label_ids_shape\": \"int64\",\n    \"toy_cls_label_ids_shape_value\": [],\n    \"toy_seq_tag_label_ids\": \"int64\",\n    \"toy_seq_tag_label_ids_shape_value\": [\n        null\n    ],\n    \"toy_seq_tag_label_ids_shape\": \"int64\"\n}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# the problem chained by & create one TFRecord folder\n",
    "json_path = os.path.join(params.tmp_file_dir, 'toy_cls_toy_seq_tag', 'train_feature_desc.json')\n",
    "print(json.dumps(json.load(open(json_path, 'r', encoding='utf8')), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
