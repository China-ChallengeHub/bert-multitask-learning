{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[python](https://img.shields.io/badge/python%20-3.6.0-brightgreen.svg) [![tensorflow](https://img.shields.io/badge/tensorflow-1.13.1-green.svg)](https://www.tensorflow.org/) [![PyPI version fury.io](https://badge.fury.io/py/ansicolortags.svg)](https://pypi.python.org/pypi/bert-multitask-learning/) [![PyPI license](https://img.shields.io/pypi/l/ansicolortags.svg)](https://pypi.python.org/pypi/bert-multitask-learning/)\n",
    "\n",
    "\n",
    "# Bert for Multi-task Learning\n",
    "\n",
    "[中文文档](#Bert多任务学习)\n",
    "\n",
    "**Note: Since 0.4.0, tf version >= 2.1 is required.**\n",
    "\n",
    "## Install\n",
    "\n",
    "```\n",
    "pip install bert-multitask-learning\n",
    "```\n",
    "\n",
    "## What is it\n",
    "\n",
    "This a project that uses [BERT](https://github.com/google-research/bert) to do **multi-task learning** with multiple GPU support.\n",
    "\n",
    "## Why do I need this\n",
    "\n",
    "In the original BERT code, neither multi-task learning or multiple GPU training is possible. Plus, the original purpose of this project is NER which dose not have a working script in the original BERT code.\n",
    "\n",
    "To sum up, compared to the original bert repo, this repo has the following features:\n",
    "\n",
    "1. Multi-task learning(major reason of re-writing the majority of code).\n",
    "2. Multiple GPU training\n",
    "3. Support sequence labeling (for example, NER) and Encoder-Decoder Seq2Seq(with transformer decoder).\n",
    "\n",
    "## What type of problems are supported?\n",
    "\n",
    "- Masked LM and next sentence prediction Pre-train(pretrain)\n",
    "- Classification(cls)\n",
    "- Sequence Labeling(seq_tag)\n",
    "- Seq2seq Labeling(seq2seq_tag)\n",
    "- Seq2seq Text Generation(seq2seq_text)\n",
    "- Multi-Label Classification(multi_cls)\n",
    "\n",
    "## How to run pre-defined problems\n",
    "\n",
    "There are two types of chaining operations can be used to chain problems.\n",
    "\n",
    "- `&`. If two problems have the same inputs, they can be chained using `&`. Problems chained by `&` will be trained at the same time.\n",
    "- `|`. If two problems don't have the same inputs, they need to be chained using `|`. Problems chained by `|` will be sampled to train at every instance.\n",
    "\n",
    "For example, `cws|NER|weibo_ner&weibo_cws`, one problem will be sampled at each turn, say `weibo_ner&weibo_cws`, then `weibo_ner` and `weibo_cws` will trained for this turn together. Therefore, in a particular batch, some tasks might not be sampled, and their loss could be 0 in this batch.\n",
    "\n",
    "Please see the examples in [notebooks](notebooks/) for more details about training, evaluation and export models.\n",
    "\n",
    "\n",
    "# Bert多任务学习\n",
    "\n",
    "**注意：版本0.4.0后要求tf>=2.1**\n",
    "\n",
    "## 安装\n",
    "\n",
    "```\n",
    "pip install bert-multitask-learning\n",
    "```\n",
    "\n",
    "## 这是什么\n",
    "\n",
    "这是利用[BERT](https://github.com/google-research/bert)进行**多任务学习**并且支持多GPU训练的项目.\n",
    "\n",
    "## 我为什么需要这个项目\n",
    "\n",
    "在原始的BERT代码中, 是没有办法直接用多GPU进行多任务学习的. 另外, BERT并没有给出序列标注和Seq2seq的训练代码.\n",
    "\n",
    "因此, 和原来的BERT相比, 这个项目具有以下特点:\n",
    "\n",
    "1. 多任务学习\n",
    "2. 多GPU训练\n",
    "3. 序列标注以及Encoder-decoder seq2seq的支持(用transformer decoder)\n",
    "\n",
    "## 目前支持的任务类型\n",
    "\n",
    "- Masked LM和next sentence prediction预训练(pretrain)\n",
    "- 单标签分类(cls)\n",
    "- 序列标注(seq_tag)\n",
    "- 序列到序列标签标注(seq2seq_tag)\n",
    "- 序列到序列文本生成(seq2seq_text)\n",
    "- 多标签分类(multi_cls)\n",
    "\n",
    "## 如何运行预定义任务\n",
    "\n",
    "### 目前支持的任务\n",
    "\n",
    "- 中文命名实体识别\n",
    "- 中文分词\n",
    "- 中文词性标注\n",
    "\n",
    "\n",
    "可以用两种方法来将多个任务连接起来.\n",
    "\n",
    "- `&`. 如果两个任务有相同的输入, 不同标签的话, 那么他们**可以**用`&`来连接. 被`&`连接起来的任务会被同时训练.\n",
    "- `|`. 如果两个任务为不同的输入, 那么他们**必须**用`|`来连接. 被`|`连接起来的任务会被随机抽取来训练.\n",
    "\n",
    "例如, 我们定义任务`cws|NER|weibo_ner&weibo_cws`, 那么在生成每一条数据时, 一个任务块会被随机抽取出来, 例如在这一次抽样中, `weibo_ner&weibo_cws`被选中. 那么这次`weibo_ner`和`weibo_cws`会被同时训练. 因此, 在一个batch中, 有可能某些任务没有被抽中, loss为0.\n",
    "\n",
    "训练, eval和导出模型请见[notebooks](notebooks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install your_proect_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
