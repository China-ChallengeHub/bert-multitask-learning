---

title: Run Bert Multitask Learning


keywords: fastai
sidebar: home_sidebar



nb_path: "source_nbs/14_run_bert_multitask.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: source_nbs/14_run_bert_multitask.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;-1&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="create_keras_model" class="doc_header"><code>create_keras_model</code><a href="https://github.com/JayYip/bert_multitask_learning/tree/master/bert_multitask_learning/run_bert_multitask.py#L26" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>create_keras_model</code>(<strong><code>mirrored_strategy</code></strong>:<code>MirroredStrategy</code>, <strong><code>params</code></strong>:<a href="/bert_multitask_learning/params.html#BaseParams"><code>BaseParams</code></a>, <strong><code>mode</code></strong>=<em><code>'train'</code></em>, <strong><code>inputs_to_build_model</code></strong>=<em><code>None</code></em>, <strong><code>model</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>init model in various mode</p>
<p>train: model will be loaded from huggingface
resume: model will be loaded from params.ckpt_dir, if params.ckpt_dir dose not contain valid checkpoint, then load from huggingface
transfer: model will be loaded from params.init_checkpoint, the correspongding path should contain checkpoints saved using bert-multitask-learning
predict: model will be loaded from params.ckpt_dir except optimizers' states
eval: model will be loaded from params.ckpt_dir except optimizers' states, model will be compiled</p>
<p>Args:
    mirrored_strategy (tf.distribute.MirroredStrategy): mirrored strategy
    params (BaseParams): params
    mode (str, optional): Mode, see above explaination. Defaults to 'train'.
    inputs_to_build_model (Dict, optional): A batch of data. Defaults to None.
    model (Model, optional): Keras model. Defaults to None.</p>
<p>Returns:
    model: loaded model</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_params_ready" class="doc_header"><code>get_params_ready</code><a href="https://github.com/JayYip/bert_multitask_learning/tree/master/bert_multitask_learning/run_bert_multitask.py#L140" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_params_ready</code>(<strong><code>problem</code></strong>, <strong><code>num_gpus</code></strong>, <strong><code>model_dir</code></strong>, <strong><code>params</code></strong>, <strong><code>problem_type_dict</code></strong>, <strong><code>processing_fn_dict</code></strong>, <strong><code>mode</code></strong>=<em><code>'train'</code></em>, <strong><code>json_path</code></strong>=<em><code>''</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="train_bert_multitask" class="doc_header"><code>train_bert_multitask</code><a href="https://github.com/JayYip/bert_multitask_learning/tree/master/bert_multitask_learning/run_bert_multitask.py#L165" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>train_bert_multitask</code>(<strong><code>problem</code></strong>=<em><code>'weibo_ner'</code></em>, <strong><code>num_gpus</code></strong>=<em><code>1</code></em>, <strong><code>num_epochs</code></strong>=<em><code>10</code></em>, <strong><code>model_dir</code></strong>=<em><code>''</code></em>, <strong><code>params</code></strong>:<a href="/bert_multitask_learning/params.html#BaseParams"><code>BaseParams</code></a>=<em><code>None</code></em>, <strong><code>problem_type_dict</code></strong>:<code>Dict</code>[<code>str</code>, <code>str</code>]=<em><code>None</code></em>, <strong><code>processing_fn_dict</code></strong>:<code>Dict</code>[<code>str</code>, <code>Callable</code>]=<em><code>None</code></em>, <strong><code>model</code></strong>:<code>Model</code>=<em><code>None</code></em>, <strong><code>create_tf_record_only</code></strong>=<em><code>False</code></em>, <strong><code>steps_per_epoch</code></strong>=<em><code>None</code></em>, <strong><code>warmup_ratio</code></strong>=<em><code>0.1</code></em>, <strong><code>continue_training</code></strong>=<em><code>False</code></em>, <strong><code>mirrored_strategy</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Train Multi-task Bert model</p>
<p>About problem:
    There are two types of chaining operations can be used to chain problems.</p>

<pre><code>    - `&amp;`. If two problems have the same inputs, they can be chained using `&amp;`.
        Problems chained by `&amp;` will be trained at the same time.
    - `|`. If two problems don't have the same inputs, they need to be chained using `|`.
        Problems chained by `|` will be sampled to train at every instance.

For example, `cws|NER|weibo_ner&amp;weibo_cws`, one problem will be sampled at each turn, say `weibo_ner&amp;weibo_cws`, then `weibo_ner` and `weibo_cws` will trained for this turn together. Therefore, in a particular batch, some tasks might not be sampled, and their loss could be 0 in this batch.

</code></pre>
<p>About problem_type_dict and processing_fn_dict:
    If the problem is not predefined, you need to tell the model what's the new problem's problem_type
    and preprocessing function.
        For example, a new problem: fake_classification
        problem_type_dict = {'fake_classification': 'cls'}
        processing_fn_dict = {'fake_classification': lambda: return ...}</p>

<pre><code>Available problem type:
    cls: Classification
    seq_tag: Sequence Labeling
    seq2seq_tag: Sequence to Sequence tag problem
    seq2seq_text: Sequence to Sequence text generation problem

Preprocessing function example:
Please refer to https://github.com/JayYip/bert-multitask-learning/blob/master/README.md

</code></pre>
<p>Keyword Arguments:
    problem {str} -- Problems to train (default: {'weibo_ner'})
    num_gpus {int} -- Number of GPU to use (default: {1})
    num_epochs {int} -- Number of epochs to train (default: {10})
    model_dir {str} -- model dir (default: {''})
    params {BaseParams} -- Params to define training and models (default: {DynamicBatchSizeParams()})
    problem_type_dict {dict} -- Key: problem name, value: problem type (default: {{}})
    processing_fn_dict {dict} -- Key: problem name, value: problem data preprocessing fn (default: {{}})</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train-multitask">Train multitask<a class="anchor-link" href="#Train-multitask"> </a></h2><p>Before training, we need to do the following things:</p>
<ul>
<li>pass transformers corresponding configuration to params, we use <code>voidful/albert_chinese_tiny</code> as example here</li>
<li>configure the problems we want to train, which includes<ul>
<li>training problems</li>
<li>their problem type as a dict</li>
<li>their preprocessing functions as a dict</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">from</span> <span class="nn">bert_multitask_learning.predefined_problems</span> <span class="kn">import</span> <span class="o">*</span>

<span class="kn">from</span> <span class="nn">bert_multitask_learning</span> <span class="kn">import</span> <span class="n">DynamicBatchSizeParams</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">bert_multitask_learning</span> <span class="kn">import</span> <span class="n">predict_input_fn</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">DynamicBatchSizeParams</span><span class="p">()</span>
<span class="n">params</span><span class="o">.</span><span class="n">shuffle_buffer</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># configure transformers</span>
<span class="n">params</span><span class="o">.</span><span class="n">transformer_tokenizer_loading</span> <span class="o">=</span> <span class="s1">&#39;BertTokenizer&#39;</span>
<span class="n">params</span><span class="o">.</span><span class="n">transformer_model_loading</span> <span class="o">=</span> <span class="s1">&#39;AlbertForMaskedLM&#39;</span>
<span class="n">params</span><span class="o">.</span><span class="n">transformer_config_loading</span> <span class="o">=</span> <span class="s1">&#39;AlbertConfig&#39;</span>
<span class="n">params</span><span class="o">.</span><span class="n">transformer_model_name</span> <span class="o">=</span> <span class="s1">&#39;voidful/albert_chinese_tiny&#39;</span>
<span class="n">params</span><span class="o">.</span><span class="n">transformer_config_name</span> <span class="o">=</span> <span class="s1">&#39;voidful/albert_chinese_tiny&#39;</span>
<span class="n">params</span><span class="o">.</span><span class="n">transformer_tokenizer_name</span> <span class="o">=</span> <span class="s1">&#39;voidful/albert_chinese_tiny&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">problem</span> <span class="o">=</span> <span class="s1">&#39;weibo_fake_ner&amp;weibo_fake_cls|weibo_fake_multi_cls|weibo_masklm|weibo_pretrain&#39;</span>
<span class="n">problem_type_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;weibo_fake_ner&#39;</span><span class="p">:</span> <span class="s1">&#39;seq_tag&#39;</span><span class="p">,</span>
    <span class="s1">&#39;weibo_cws&#39;</span><span class="p">:</span> <span class="s1">&#39;seq_tag&#39;</span><span class="p">,</span>
    <span class="s1">&#39;weibo_fake_multi_cls&#39;</span><span class="p">:</span> <span class="s1">&#39;multi_cls&#39;</span><span class="p">,</span>
    <span class="s1">&#39;weibo_fake_cls&#39;</span><span class="p">:</span> <span class="s1">&#39;cls&#39;</span><span class="p">,</span>
    <span class="s1">&#39;weibo_masklm&#39;</span><span class="p">:</span> <span class="s1">&#39;masklm&#39;</span><span class="p">,</span>
    <span class="s1">&#39;weibo_pretrain&#39;</span><span class="p">:</span> <span class="s1">&#39;pretrain&#39;</span>
<span class="p">}</span>

<span class="n">processing_fn_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;weibo_fake_ner&#39;</span><span class="p">:</span> <span class="n">get_weibo_fake_ner_fn</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="s1">&#39;/data/bert-multitask-learning/data/ner/weiboNER*&#39;</span><span class="p">),</span>
    <span class="s1">&#39;weibo_cws&#39;</span><span class="p">:</span> <span class="n">get_weibo_cws_fn</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="s1">&#39;/data/bert-multitask-learning/data/ner/weiboNER*&#39;</span><span class="p">),</span>
    <span class="s1">&#39;weibo_fake_cls&#39;</span><span class="p">:</span> <span class="n">get_weibo_fake_cls_fn</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="s1">&#39;/data/bert-multitask-learning/data/ner/weiboNER*&#39;</span><span class="p">),</span>
    <span class="s1">&#39;weibo_fake_multi_cls&#39;</span><span class="p">:</span> <span class="n">get_weibo_fake_multi_cls_fn</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="s1">&#39;/data/bert-multitask-learning/data/ner/weiboNER*&#39;</span><span class="p">),</span>
    <span class="s1">&#39;weibo_masklm&#39;</span><span class="p">:</span> <span class="n">get_weibo_masklm</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="s1">&#39;/data/bert-multitask-learning/data/ner/weiboNER*&#39;</span><span class="p">),</span>
    <span class="s1">&#39;weibo_pretrain&#39;</span><span class="p">:</span> <span class="n">get_weibo_pretrain_fn</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="s1">&#39;/data/bert-multitask-learning/data/ner/weiboNER*&#39;</span><span class="p">)</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered celltag_outputPrepend">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">train_bert_multitask</span><span class="p">(</span>
    <span class="n">problem</span><span class="o">=</span><span class="n">problem</span><span class="p">,</span>
    <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
    <span class="n">problem_type_dict</span><span class="o">=</span><span class="n">problem_type_dict</span><span class="p">,</span>
    <span class="n">processing_fn_dict</span><span class="o">=</span><span class="n">processing_fn_dict</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">continue_training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">mirrored_strategy</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>101, 2458, 1297, 749, 8024, 103, 1157, 103, 103, 103, 1378, 103, 2769, 103, 2207, 5101, 2797, 3322, 1728, 711, 800, 3221, 103, 791, 103, 103, 3297, 2571, 103, 2207, 5101, 2797,
INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_positions: [1, 9, 11, 12, 13, 15, 17, 26, 28, 29, 32, 39, 52, 58, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_ids: [1420 1157 7564 5276  749  511 4263 6812  711 3632 4638  704 5101 5276
    0    0    0    0    0    0]
INFO:tensorflow:masked_lm_weights: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0]
INFO:tensorflow:[&#39;最&#39;, &#39;热&#39;, &#39;时&#39;, &#39;尚&#39;, &#39;榜&#39;, &#39;女&#39;, &#39;人&#39;, &#39;不&#39;, &#39;坏&#39;, &#39;，&#39;, &#39;男&#39;, &#39;人&#39;, &#39;不&#39;, &#39;爱&#39;, &#39;，&#39;, &#39;一&#39;, &#39;个&#39;, &#39;男&#39;, &#39;女&#39;, &#39;必&#39;, &#39;看&#39;, &#39;的&#39;, &#39;微&#39;, &#39;博&#39;, &#39;花&#39;, &#39;心&#39;]
INFO:tensorflow:input_ids: [101, 3297, 4178, 3198, 2213, 103, 1957, 782, 679, 1776, 8024, 4511, 782, 679, 4263, 8024, 671, 702, 4511, 1957, 2553, 4692, 103, 2544, 1300, 5709, 2552, 102]
INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_positions: [5, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_ids: [3528 4638    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0]
INFO:tensorflow:masked_lm_weights: [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
INFO:tensorflow:[&#39;回&#39;, &#39;复&#39;, &#39;支&#39;, &#39;持&#39;, &#39;，&#39;, &#39;赞&#39;, &#39;成&#39;, &#39;，&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;米&#39;, &#39;八&#39;, &#39;吴&#39;, &#39;够&#39;, &#39;历&#39;, &#39;史&#39;, &#39;要&#39;, &#39;的&#39;, &#39;陈&#39;, &#39;小&#39;, &#39;奥&#39;, &#39;丁&#39;, &#39;丁&#39;, &#39;我&#39;, &#39;爱&#39;, &#39;小&#39;, &#39;肥&#39;, &#39;肥&#39;, &#39;一&#39;, &#39;族&#39;, &#39;大&#39;, &#39;头&#39;, &#39;仔&#39;, &#39;大&#39;, &#39;家&#39;, &#39;团&#39;, &#39;结&#39;, &#39;一&#39;, &#39;致&#39;, &#39;，&#39;,
INFO:tensorflow:input_ids: [101, 1726, 1908, 3118, 103, 103, 6614, 2768, 8024, 103, 1506, 5101, 103, 1426, 1916, 1325, 1380, 6206, 4638, 7357, 2207, 1952, 672, 672, 103, 4263, 103, 5503, 103, 671, 3184, 1920, 103, 798, 1920, 21
INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_positions: [4, 5, 9, 12, 24, 26, 28, 32, 44, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_ids: [2898 8024 1506 1061 2769 2207 5503 1928 1378 7030    0    0    0    0
    0    0    0    0    0    0]
INFO:tensorflow:masked_lm_weights: [1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]
INFO:tensorflow:[&#39;剑&#39;, &#39;网&#39;, &#39;乱&#39;, &#39;世&#39;, &#39;长&#39;, &#39;安&#39;, &#39;公&#39;, &#39;测&#39;, &#39;盛&#39;, &#39;典&#39;, &#39;今&#39;, &#39;日&#39;, &#39;开&#39;, &#39;启&#39;, &#39;，&#39;, &#39;海&#39;, &#39;量&#39;, &#39;豪&#39;, &#39;礼&#39;, &#39;火&#39;, &#39;爆&#39;, &#39;开&#39;, &#39;送&#39;, &#39;精&#39;, &#39;美&#39;, &#39;挂&#39;, &#39;件&#39;, &#39;、&#39;, &#39;听&#39;, &#39;雨&#39;, &#39;·&#39;, &#39;汉&#39;, &#39;服&#39;, &#39;娃&#39;, &#39;娃&#39;, &#39;、&#39;, &#39;诙&#39;, &#39;谐&#39;, &#39;双&#39;, &#39;骑&#39;,
INFO:tensorflow:input_ids: [101, 1187, 5381, 744, 686, 7270, 2128, 1062, 3844, 103, 1073, 791, 3189, 2458, 1423, 8024, 3862, 7030, 6498, 103, 4125, 103, 2458, 103, 5125, 5401, 103, 816, 510, 1420, 7433, 185, 3727, 103, 2015, 20
INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1
INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
INFO:tensorflow:masked_lm_positions: [9, 19, 21, 23, 26, 33, 42, 51, 54, 76, 82, 86, 87, 89, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_ids: [4670 4851 4255 6843 2899 3302 6762 1283 5101 1346 2544 2145 2787 1218
    0    0    0    0    0    0]
INFO:tensorflow:masked_lm_weights: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0]
INFO:tensorflow:[&#39;在&#39;, &#39;街&#39;, &#39;上&#39;, &#39;听&#39;, &#39;见&#39;, &#39;音&#39;, &#39;乐&#39;, &#39;我&#39;, &#39;舞&#39;, &#39;动&#39;, &#39;起&#39;, &#39;来&#39;, &#39;很&#39;, &#39;丢&#39;, &#39;人&#39;, &#39;？&#39;, &#39;真&#39;, &#39;的&#39;, &#39;很&#39;, &#39;丢&#39;, &#39;人&#39;, &#39;吗&#39;, &#39;？&#39;]
INFO:tensorflow:input_ids: [101, 1762, 6125, 103, 1420, 6224, 103, 727, 2769, 5659, 1220, 6629, 3341, 2523, 696, 782, 103, 4696, 103, 2523, 696, 782, 103, 8043, 102]
INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_positions: [3, 6, 16, 18, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_ids: [ 677 7509 8043 4638 1408    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0]
INFO:tensorflow:masked_lm_weights: [1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
INFO:tensorflow:[&#39;三&#39;, &#39;毛&#39;, &#39;说&#39;, &#39;我&#39;, &#39;唯&#39;, &#39;一&#39;, &#39;锲&#39;, &#39;而&#39;, &#39;不&#39;, &#39;舍&#39;, &#39;，&#39;, &#39;愿&#39;, &#39;意&#39;, &#39;以&#39;, &#39;自&#39;, &#39;己&#39;, &#39;的&#39;, &#39;生&#39;, &#39;命&#39;, &#39;去&#39;, &#39;努&#39;, &#39;力&#39;, &#39;的&#39;, &#39;，&#39;, &#39;只&#39;, &#39;不&#39;, &#39;过&#39;, &#39;是&#39;, &#39;保&#39;, &#39;守&#39;, &#39;我&#39;, &#39;个&#39;, &#39;人&#39;, &#39;的&#39;, &#39;心&#39;, &#39;怀&#39;, &#39;意&#39;, &#39;念&#39;, &#39;，&#39;, &#39;在&#39;,
INFO:tensorflow:input_ids: [101, 676, 3688, 6432, 2769, 1546, 671, 7244, 5445, 679, 103, 8024, 2703, 2692, 809, 103, 2346, 4638, 4495, 1462, 1343, 1222, 1213, 4638, 8024, 1372, 103, 6814, 3221, 924, 2127, 2769, 702, 782, 4638, 
INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1
INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
INFO:tensorflow:masked_lm_positions: [10, 15, 26, 37, 58, 68, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_ids: [5650 5632  679 2692 2190 1762    0    0    0    0    0    0    0    0
    0    0    0    0    0    0]
INFO:tensorflow:masked_lm_weights: [1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
INFO:tensorflow:[&#39;星&#39;, &#39;期&#39;, &#39;天&#39;, &#39;的&#39;, &#39;早&#39;, &#39;晨&#39;, &#39;七&#39;, &#39;点&#39;, &#39;学&#39;, &#39;车&#39;, &#39;，&#39;, &#39;驾&#39;, &#39;校&#39;, &#39;太&#39;, &#39;给&#39;, &#39;力&#39;, &#39;。&#39;, &#39;我&#39;, &#39;的&#39;, &#39;头&#39;, &#39;发&#39;, &#39;都&#39;, &#39;没&#39;, &#39;有&#39;, &#39;洗&#39;]
INFO:tensorflow:input_ids: [101, 3215, 3309, 1921, 4638, 103, 3247, 673, 103, 103, 6756, 8024, 103, 3413, 1922, 5314, 1213, 511, 2769, 4638, 1928, 1355, 103, 3766, 3300, 3819, 102]
INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_positions: [5, 8, 9, 12, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_ids: [3193 4157 2110 7730 6963    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0]
INFO:tensorflow:masked_lm_weights: [1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
INFO:tensorflow:[&#39;发&#39;, &#39;表&#39;, &#39;了&#39;, &#39;博&#39;, &#39;文&#39;, &#39;小&#39;, &#39;学&#39;, &#39;美&#39;, &#39;术&#39;, &#39;新&#39;, &#39;课&#39;, &#39;标&#39;, &#39;的&#39;, &#39;反&#39;, &#39;思&#39;, &#39;学&#39;, &#39;习&#39;, &#39;新&#39;, &#39;学&#39;, &#39;期&#39;, &#39;开&#39;, &#39;学&#39;, &#39;有&#39;, &#39;两&#39;, &#39;个&#39;, &#39;多&#39;, &#39;月&#39;, &#39;了&#39;, &#39;，&#39;, &#39;在&#39;, &#39;这&#39;, &#39;段&#39;, &#39;时&#39;, &#39;间&#39;, &#39;的&#39;, &#39;教&#39;, &#39;学&#39;, &#39;计&#39;, &#39;划&#39;, &#39;、&#39;,
INFO:tensorflow:input_ids: [101, 1355, 6134, 749, 103, 3152, 103, 2110, 5401, 3318, 3173, 6440, 3403, 4638, 1353, 2590, 2110, 103, 3173, 2110, 3309, 2458, 2110, 3300, 697, 702, 1914, 3299, 103, 8024, 1762, 6821, 3667, 103, 7313
INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1
INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
INFO:tensorflow:masked_lm_positions: [4, 6, 17, 28, 33, 37, 56, 62, 68, 73, 77, 81, 85, 88, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_ids: [1300 2207  739  749 3198 2110 3318 3300 6371 4385 4638 3418 2552 4157
    0    0    0    0    0    0]
INFO:tensorflow:masked_lm_weights: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0]
INFO:tensorflow:[&#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;镰&#39;, &#39;刀&#39;, &#39;刮&#39;, &#39;腋&#39;, &#39;毛&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;我&#39;, &#39;的&#39;, &#39;朋&#39;, &#39;友&#39;, &#39;是&#39;, &#39;个&#39;, &#39;呆&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;哈&#39;, &#39;十&#39;, &#39;万&#39;, &#39;个&#39;,
INFO:tensorflow:input_ids: [101, 1506, 1506, 1506, 1506, 1506, 103, 7266, 1143, 1167, 5573, 3688, 1506, 1506, 1506, 103, 1506, 1506, 103, 4638, 3301, 1351, 3221, 702, 1438, 1506, 1506, 1506, 1506, 103, 1506, 1506, 1506, 1506, 1
INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1
INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
INFO:tensorflow:masked_lm_positions: [6, 15, 18, 29, 53, 69, 73, 87, 93, 97, 98, 105, 0, 0, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_ids: [1506 1506 2769 1506 1506 3683 4331 1541 1506 3392 7448 1506    0    0
    0    0    0    0    0    0]
INFO:tensorflow:masked_lm_weights: [1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]
INFO:tensorflow:[&#39;�&#39;, &#39;�&#39;, &#39;就&#39;, &#39;爱&#39;, &#39;这&#39;, &#39;个&#39;, &#39;牌&#39;, &#39;子&#39;, &#39;的&#39;, &#39;糖&#39;, &#39;果&#39;]
INFO:tensorflow:input_ids: [101, 2218, 4263, 6821, 702, 103, 2094, 4638, 5131, 103, 102]
INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_positions: [5, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_ids: [4277 3362    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0]
INFO:tensorflow:masked_lm_weights: [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
INFO:tensorflow:[&#39;延&#39;, &#39;参&#39;, &#39;法&#39;, &#39;师&#39;, &#39;品&#39;, &#39;味&#39;, &#39;人&#39;, &#39;生&#39;, &#39;如&#39;, &#39;同&#39;, &#39;走&#39;, &#39;进&#39;, &#39;一&#39;, &#39;片&#39;, &#39;山&#39;, &#39;水&#39;, &#39;，&#39;, &#39;静&#39;, &#39;静&#39;, &#39;的&#39;, &#39;呼&#39;, &#39;吸&#39;, &#39;，&#39;, &#39;安&#39;, &#39;静&#39;, &#39;的&#39;, &#39;欣&#39;, &#39;赏&#39;, &#39;，&#39;, &#39;这&#39;, &#39;就&#39;, &#39;是&#39;, &#39;生&#39;, &#39;活&#39;, &#39;。&#39;]
INFO:tensorflow:input_ids: [101, 2454, 1346, 3791, 2360, 1501, 1456, 103, 4495, 1963, 1398, 6624, 103, 671, 4275, 2255, 3717, 8024, 7474, 7474, 4638, 1461, 1429, 8024, 2128, 7474, 4638, 3615, 6605, 103, 6821, 2218, 3221, 103, 3
INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_positions: [7, 12, 29, 33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_ids: [ 782 6822 8024 4495    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0]
INFO:tensorflow:masked_lm_weights: [1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
INFO:tensorflow:[&#39;就&#39;, &#39;感&#39;, &#39;恩&#39;, &#39;吧&#39;, &#39;越&#39;, &#39;来&#39;, &#39;越&#39;, &#39;没&#39;, &#39;战&#39;, &#39;斗&#39;, &#39;力&#39;, &#39;了&#39;, &#39;。&#39;]
INFO:tensorflow:input_ids: [101, 2218, 103, 2617, 1416, 6632, 3341, 6632, 3766, 2773, 3159, 1213, 749, 511, 102]
INFO:tensorflow:input_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
INFO:tensorflow:segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_positions: [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
INFO:tensorflow:masked_lm_ids: [2697    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0]
INFO:tensorflow:masked_lm_weights: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
INFO:tensorflow:sampling weights: 
INFO:tensorflow:weibo_fake_cls_weibo_fake_ner: 0.4
INFO:tensorflow:weibo_fake_multi_cls: 0.2
INFO:tensorflow:weibo_masklm: 0.2
INFO:tensorflow:weibo_pretrain: 0.2
INFO:tensorflow:sampling weights: 
INFO:tensorflow:weibo_fake_cls_weibo_fake_ner: 0.4
INFO:tensorflow:weibo_fake_multi_cls: 0.2
INFO:tensorflow:weibo_masklm: 0.2
INFO:tensorflow:weibo_pretrain: 0.2
INFO:tensorflow:sampling weights: 
INFO:tensorflow:weibo_fake_cls_weibo_fake_ner: 0.4
INFO:tensorflow:weibo_fake_multi_cls: 0.2
INFO:tensorflow:weibo_masklm: 0.2
INFO:tensorflow:weibo_pretrain: 0.2
404 Client Error: Not Found for url: https://huggingface.co/voidful/albert_chinese_tiny/resolve/main/tf_model.h5
Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: [&#39;predictions.LayerNorm.bias&#39;, &#39;predictions.decoder.bias&#39;, &#39;predictions.LayerNorm.weight&#39;, &#39;predictions.dense.bias&#39;, &#39;predictions.bias&#39;, &#39;predictions.dense.weight&#39;, &#39;predictions.decoder.weight&#39;]
- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
All the weights of TFAlbertModel were initialized from the PyTorch model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.
WARNING:tensorflow:From /data/anaconda3/lib/python3.8/inspect.py:350: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /data/anaconda3/lib/python3.8/inspect.py:350: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:root:Share embedding is enabled but hidden_size != embedding_size
WARNING:root:Share embedding is enabled but hidden_size != embedding_size
INFO:tensorflow:Initial lr: 2e-05
INFO:tensorflow:Train steps: 1
INFO:tensorflow:Warmup steps: 0
WARNING:tensorflow:Seems there&#39;s a multimodal inputs but params.enable_modal_type is not set to be True.
WARNING:tensorflow:5 out of the last 5 calls to &lt;function BertMultiTaskBody.get_features_for_problem at 0x7f3e95b1bee0&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:Seems there&#39;s a multimodal inputs but params.enable_modal_type is not set to be True.
WARNING:tensorflow:AutoGraph could not transform &lt;bound method Socket.send of &lt;zmq.sugar.socket.Socket object at 0x7f3f401db2e0&gt;&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform &lt;bound method Socket.send of &lt;zmq.sugar.socket.Socket object at 0x7f3f401db2e0&gt;&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
WARNING:tensorflow:Seems there&#39;s a multimodal inputs but params.enable_modal_type is not set to be True.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
1/1 [==============================] - ETA: 0s - mean_acc: 0.2095 - weibo_fake_cls_acc: 0.0000e+00 - weibo_fake_ner_acc: 0.4189 - weibo_fake_ner_loss: 1.6564 - weibo_fake_cls_loss: 1.4976 - weibo_fake_multi_cls_loss: 1.3982 - weibo_masklm_loss: 9.9856 - weibo_pretrain_loss: 10.6494WARNING:tensorflow:Seems there&#39;s a multimodal inputs but params.enable_modal_type is not set to be True.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
1/1 [==============================] - 7s 7s/step - mean_acc: 0.2095 - weibo_fake_cls_acc: 0.0000e+00 - weibo_fake_ner_acc: 0.4189 - weibo_fake_ner_loss: 1.6564 - weibo_fake_cls_loss: 1.4976 - weibo_fake_multi_cls_loss: 1.3982 - weibo_masklm_loss: 9.9856 - weibo_pretrain_loss: 10.6494 - val_loss: 16.8679 - val_mean_acc: 0.4195 - val_weibo_fake_cls_acc: 0.5500 - val_weibo_fake_ner_acc: 0.3088
Model: &#34;BertMultiTask&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
BertMultiTaskBody (BertMulti multiple                  4081928   
_________________________________________________________________
BertMultiTaskTop (BertMultiT multiple                  13231453  
_________________________________________________________________
mean_acc (Mean)              multiple                  2         
=================================================================
Total params: 17,313,383
Trainable params: 17,313,377
Non-trainable params: 6
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="trim_checkpoint_for_prediction" class="doc_header"><code>trim_checkpoint_for_prediction</code><a href="https://github.com/JayYip/bert_multitask_learning/tree/master/bert_multitask_learning/run_bert_multitask.py#L273" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>trim_checkpoint_for_prediction</code>(<strong><code>problem</code></strong>:<code>str</code>, <strong><code>input_dir</code></strong>:<code>str</code>, <strong><code>output_dir</code></strong>:<code>str</code>, <strong><code>problem_type_dict</code></strong>:<code>Dict</code>[<code>str</code>, <code>str</code>]=<em><code>None</code></em>, <strong><code>overwrite</code></strong>=<em><code>True</code></em>, <strong><code>fake_input_list</code></strong>=<em><code>None</code></em>, <strong><code>params</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Minimize checkpoint size for prediction.</p>
<p>Since the original checkpoint contains optimizer's variable,
    for instance, if the use adam, the checkpoint size will
    be three times of the size of model weights. This function
    will remove those unused variables in prediction to save space.</p>
<p>Note: if the model is a multimodal model, you have to provide fake_input_list that
    mimic the structure of real input.</p>
<p>Args:
    problem (str): problem
    input_dir (str): input dir
    output_dir (str): output dir
    problem_type_dict (Dict[str, str], optional): problem type dict. Defaults to None.
    fake_input_list (List): fake input list to create dummy dataset</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Trim-checkpoints">Trim checkpoints<a class="anchor-link" href="#Trim-checkpoints"> </a></h2><p>The checkpoints contains optimizers' states which is not needed once training is done and it makes the checkpoint size two times larger. We provide an api to trim down the size of checkpoint by removing optimizers' states.</p>
<p>Note: in multimodal setting, you need to provide a fake input to build the model correctly. Otherwise modal embeddings will be randomly initialized.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">get_logger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="s1">&#39;ERROR&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">fake_inputs</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
            <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">))}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span> 
<span class="n">trim_checkpoint_for_prediction</span><span class="p">(</span>
    <span class="n">problem</span><span class="o">=</span><span class="n">problem</span><span class="p">,</span> <span class="n">input_dir</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">ckpt_dir</span><span class="p">,</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">ckpt_dir</span><span class="o">+</span><span class="s1">&#39;_pred&#39;</span><span class="p">,</span>
    <span class="n">problem_type_dict</span><span class="o">=</span><span class="n">problem_type_dict</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fake_input_list</span><span class="o">=</span><span class="n">fake_inputs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Adding new problem weibo_fake_ner, problem type: seq_tag
Adding new problem weibo_cws, problem type: seq_tag
Adding new problem weibo_fake_multi_cls, problem type: multi_cls
Adding new problem weibo_fake_cls, problem type: cls
Adding new problem weibo_masklm, problem type: masklm
Adding new problem weibo_pretrain, problem type: pretrain
WARNING:root:Share embedding is enabled but hidden_size != embedding_size
WARNING:root:Share embedding is enabled but hidden_size != embedding_size
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="eval_bert_multitask" class="doc_header"><code>eval_bert_multitask</code><a href="https://github.com/JayYip/bert_multitask_learning/tree/master/bert_multitask_learning/run_bert_multitask.py#L323" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>eval_bert_multitask</code>(<strong><code>problem</code></strong>=<em><code>'weibo_ner'</code></em>, <strong><code>num_gpus</code></strong>=<em><code>1</code></em>, <strong><code>model_dir</code></strong>=<em><code>''</code></em>, <strong><code>params</code></strong>=<em><code>None</code></em>, <strong><code>problem_type_dict</code></strong>=<em><code>None</code></em>, <strong><code>processing_fn_dict</code></strong>=<em><code>None</code></em>, <strong><code>model</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Evaluate Multi-task Bert model</p>
<p>Available eval_scheme:
    ner, cws, acc</p>
<p>Keyword Arguments:
    problem {str} -- problems to evaluate (default: {'weibo_ner'})
    num_gpus {int} -- number of gpu to use (default: {1})
    model_dir {str} -- model dir (default: {''})
    eval_scheme {str} -- Evaluation scheme (default: {'ner'})
    params {Params} -- params to define model (default: {DynamicBatchSizeParams()})
    problem_type_dict {dict} -- Key: problem name, value: problem type (default: {{}})
    processing_fn_dict {dict} -- Key: problem name, value: problem data preprocessing fn (default: {{}})</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Eval">Eval<a class="anchor-link" href="#Eval"> </a></h1><p>Now we can use the trimmed checkpoint to do evaluation</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">eval_bert_multitask</span><span class="p">(</span><span class="n">problem</span><span class="o">=</span><span class="n">problem</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
                    <span class="n">problem_type_dict</span><span class="o">=</span><span class="n">problem_type_dict</span><span class="p">,</span> <span class="n">processing_fn_dict</span><span class="o">=</span><span class="n">processing_fn_dict</span><span class="p">,</span>
                    <span class="n">model_dir</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">ckpt_dir</span><span class="o">+</span><span class="s1">&#39;_pred&#39;</span><span class="p">)</span>

<span class="c1"># provide model instead of dir</span>
<span class="n">eval_bert_multitask</span><span class="p">(</span><span class="n">problem</span><span class="o">=</span><span class="n">problem</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
                    <span class="n">problem_type_dict</span><span class="o">=</span><span class="n">problem_type_dict</span><span class="p">,</span> <span class="n">processing_fn_dict</span><span class="o">=</span><span class="n">processing_fn_dict</span><span class="p">,</span>
                    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Adding new problem weibo_fake_ner, problem type: seq_tag
Adding new problem weibo_cws, problem type: seq_tag
Adding new problem weibo_fake_multi_cls, problem type: multi_cls
Adding new problem weibo_fake_cls, problem type: cls
Adding new problem weibo_masklm, problem type: masklm
Adding new problem weibo_pretrain, problem type: pretrain
WARNING:root:Share embedding is enabled but hidden_size != embedding_size
WARNING:root:Share embedding is enabled but hidden_size != embedding_size
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
9/9 [==============================] - 3s 329ms/step - loss: 16.5940 - mean_acc: 0.6559 - weibo_fake_cls_acc: 0.6000 - weibo_fake_ner_acc: 0.6994
Adding new problem weibo_fake_ner, problem type: seq_tag
Adding new problem weibo_cws, problem type: seq_tag
Adding new problem weibo_fake_multi_cls, problem type: multi_cls
Adding new problem weibo_fake_cls, problem type: cls
Adding new problem weibo_masklm, problem type: masklm
Adding new problem weibo_pretrain, problem type: pretrain
WARNING:root:Share embedding is enabled but hidden_size != embedding_size
WARNING:root:Share embedding is enabled but hidden_size != embedding_size
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
9/9 [==============================] - 3s 344ms/step - loss: 16.5940 - mean_acc: 0.6559 - weibo_fake_cls_acc: 0.6000 - weibo_fake_ner_acc: 0.6994
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;loss&#39;: 16.59403419494629,
 &#39;mean_acc&#39;: 0.6558765769004822,
 &#39;weibo_fake_cls_acc&#39;: 0.6000000238418579,
 &#39;weibo_fake_ner_acc&#39;: 0.699386477470398}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="predict_bert_multitask" class="doc_header"><code>predict_bert_multitask</code><a href="https://github.com/JayYip/bert_multitask_learning/tree/master/bert_multitask_learning/run_bert_multitask.py#L362" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>predict_bert_multitask</code>(<strong><code>inputs</code></strong>, <strong><code>problem</code></strong>=<em><code>'weibo_ner'</code></em>, <strong><code>model_dir</code></strong>=<em><code>''</code></em>, <strong><code>params</code></strong>:<a href="/bert_multitask_learning/params.html#BaseParams"><code>BaseParams</code></a>=<em><code>None</code></em>, <strong><code>problem_type_dict</code></strong>:<code>Dict</code>[<code>str</code>, <code>str</code>]=<em><code>None</code></em>, <strong><code>processing_fn_dict</code></strong>:<code>Dict</code>[<code>str</code>, <code>Callable</code>]=<em><code>None</code></em>, <strong><code>model</code></strong>:<code>Model</code>=<em><code>None</code></em>, <strong><code>return_model</code></strong>=<em><code>False</code></em>)</p>
</blockquote>
<p>Evaluate Multi-task Bert model</p>
<p>Available eval_scheme:
    ner, cws, acc</p>
<p>Keyword Arguments:
    problem {str} -- problems to evaluate (default: {'weibo_ner'})
    num_gpus {int} -- number of gpu to use (default: {1})
    model_dir {str} -- model dir (default: {''})
    eval_scheme {str} -- Evaluation scheme (default: {'ner'})
    params {Params} -- params to define model (default: {DynamicBatchSizeParams()})
    problem_type_dict {dict} -- Key: problem name, value: problem type (default: {{}})
    processing_fn_dict {dict} -- Key: problem name, value: problem data preprocessing fn (default: {{}})</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Predict">Predict<a class="anchor-link" href="#Predict"> </a></h2><p>We can do prediction by providing list of input features</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pred</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">predict_bert_multitask</span><span class="p">(</span>
    <span class="n">problem</span><span class="o">=</span><span class="s1">&#39;weibo_fake_ner&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="n">fake_inputs</span><span class="o">*</span><span class="mi">20</span><span class="p">,</span> <span class="n">model_dir</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">ckpt_dir</span><span class="p">,</span>
    <span class="n">problem_type_dict</span><span class="o">=</span><span class="n">problem_type_dict</span><span class="p">,</span>
    <span class="n">processing_fn_dict</span><span class="o">=</span><span class="n">processing_fn_dict</span><span class="p">,</span> <span class="n">return_model</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Adding new problem weibo_fake_ner, problem type: seq_tag
Adding new problem weibo_cws, problem type: seq_tag
Adding new problem weibo_fake_multi_cls, problem type: multi_cls
Adding new problem weibo_fake_cls, problem type: cls
Adding new problem weibo_masklm, problem type: masklm
Adding new problem weibo_pretrain, problem type: pretrain
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

